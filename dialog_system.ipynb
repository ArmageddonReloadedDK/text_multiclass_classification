{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from gensim.models import FastText,KeyedVectors,fasttext\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Activation,Reshape,Conv2D,LeakyReLU,concatenate,Flatten,Reshape\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faq(urls,question_data,answer_data):\n",
    "    #\n",
    "    #  urls - list [urls1,urls2,..]\n",
    "    #  question_data, answer_data - list [tag_value,class_value]  \n",
    "    #\n",
    "    #  return faq - list shape (n,2), where [:,0] - question, [:,1] - answer\n",
    "    #\n",
    "    question_tag,question_class=question_data\n",
    "    answer_tag,answer_class=answer_data\n",
    "    \n",
    "    rs =[ requests.get(url) for url in urls]\n",
    "    responses = [r.text.encode('utf-8') for r in rs]\n",
    "    soups = [BeautifulSoup(response) for response in responses]\n",
    "\n",
    "    faq=[]\n",
    "    for soup in soups:\n",
    "        question=soup.findAll(question_tag, class_=question_class)\n",
    "        answer=soup.findAll(answer_tag,class_=answer_class)\n",
    "        temp_questions=[]\n",
    "        temp_answers=[]\n",
    "        for q in question:\n",
    "            temp_questions.append(q.text)\n",
    "        for ans in answer:\n",
    "            temp_answers.append(ans.text)\n",
    "        \n",
    "        temp_questions=np.array(temp_questions).reshape((-1,1))\n",
    "        temp_answers=np.array(temp_answers).reshape((-1,1))\n",
    "        temp_faq=np.concatenate([temp_questions,temp_answers],axis=1)\n",
    "        faq.append(temp_faq)\n",
    "\n",
    "\n",
    "    \n",
    "    return faq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls1=['https://www.mosenergosbyt.ru/common/lobby/questions/category_5749.php',\n",
    "     'https://www.mosenergosbyt.ru/common/lobby/questions/category_5739.php',\n",
    "     'https://www.mosenergosbyt.ru/common/lobby/questions/category_48100.php',\n",
    "     'https://www.mosenergosbyt.ru/common/lobby/questions/category_48101.php',\n",
    "     'https://www.mosenergosbyt.ru/common/lobby/questions/category_48102.php',\n",
    "     'https://www.mosenergosbyt.ru/common/lobby/questions/category_48103.php',\n",
    "     'https://www.mosenergosbyt.ru/common/lobby/questions/category_5745.php',\n",
    "     'https://www.mosenergosbyt.ru/common/lobby/questions/category_5763.php',\n",
    "     'https://www.mosenergosbyt.ru/common/lobby/questions/category_5754.php',\n",
    "     'https://www.mosenergosbyt.ru/common/lobby/questions/category_5716.php']\n",
    "\n",
    "urls2=['https://mosoblgaz.ru/company/query_answer/']\n",
    "\n",
    "faq1=get_faq(urls1,['button','btn btn-link collapsed'],['div','collapse'])\n",
    "faq2=get_faq(urls2,['div','faq-list-item__title js-accordion-item-title'],\n",
    "             ['div','faq-list-item__text-inner js-accordion-item-inner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n                    Для переоформления лицевого счета на нового владельца, собственнику необходимо обратиться в любое отделение АО\\n                    «Мосэнергосбыт».\\n                \\n\\n                    При себе необходимо иметь следующие документы:\\n                \\n\\nДоговор купли-продажи;\\nСвидетельство о государственной регистрации права\\xa0собственности\\xa0(если\\n                        квартира в собственности);\\n                    \\nКопия финансового лицевого счета из жилищной организации (если квартира муниципальная);\\nПаспорт;\\nТекущие показания прибора учета на день обращения в отделение АО «Мосэнергосбыт».\\n\\n\\n                    Все документы должны быть представлены в оригинале или копии, заверенные нотариусом.\\nТакже оформить заявку на изменения данных с прикреплением необходимых документов можно в Едином личном кабинете физического лица во вкладке «Реквизиты ЛС»/Общая информация/ Изменить, далее в открывшемся списке выбрать «Собственника/нанимателя» при условии, что задолженность предыдущего собственника или нерешенные вопросы по оплате долга предыдущего собственника, отсутствуют. \\n                \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faq1[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "tar = tarfile.open(\"test.tar\", \"r\")\n",
    "tar.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search engine\n",
    "\n",
    "FastText documents embeddings vs questions\n",
    "\n",
    "document=questions+answers on one theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model= fasttext.FastTextKeyedVectors.load('214/model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(model,text):\n",
    "    for sentence in text:\n",
    "        txt=sentence.split()\n",
    "        val=0\n",
    "        for word in txt:\n",
    "            val+=model[word]\n",
    "\n",
    "    return val/len(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[]\n",
    "documents=[]\n",
    "class_num=len(faq1)\n",
    "questions2class=dict()\n",
    "quesions_classes=[]\n",
    "\n",
    "\n",
    "\n",
    "for i,document in enumerate(faq1):\n",
    "    \n",
    "    for line in document:\n",
    "        question=line[0]\n",
    "        questions.append(question)\n",
    "        questions_classes.append(i)\n",
    "        questions2class[question]=i\n",
    "        \n",
    "        \n",
    "    temp_documents=[]\n",
    "    for line in document:\n",
    "        temp_documents.append(line[0])\n",
    "        temp_documents.append(line[1])\n",
    "\n",
    "        \n",
    "    documents.append(temp_documents)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_embs=np.zeros((len(documents),300))\n",
    "for i,document in enumerate(documents):\n",
    "    documents_embs[i]=sentence_embedding(ft_model,document)\n",
    "    \n",
    "questions_embs=np.zeros((len(questions),300))\n",
    "for i,question in enumerate(questions):\n",
    "    questions_embs[i]=sentence_embedding(ft_model,[question])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_false_documents=[]\n",
    "true_questions=[]\n",
    "true_question_classes=[]\n",
    "\n",
    "for question_class,question in zip(questions_classes,questions_embs):\n",
    "    true_false_documents.append(documents_embs[question_class])\n",
    "    true_questions.append(question)\n",
    "    true_question_classes.append(question_class)\n",
    "    \n",
    "    flag=True\n",
    "    while flag:\n",
    "        rnd_index=np.random.randint(0,10)\n",
    "        if rnd_index!=question_class:\n",
    "            flag=False\n",
    "            \n",
    "    true_false_documents.append(documents_embs[rnd_index])\n",
    "    true_questions.append(question)\n",
    "    true_question_classes.append(class_num+1)\n",
    "        \n",
    "true_false_documents=np.array(true_false_documents)\n",
    "true_questions=np.array(true_questions)\n",
    "true_question_classes=np.array(true_question_classes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(41)\n",
    "\n",
    "x1_train,x1_test,y1_train,y1_test=train_test_split(true_false_documents,true_question_classes)\n",
    "\n",
    "y1_train=tf.one_hot(y1_train,depth=class_num+1)\n",
    "\n",
    "np.random.seed(41)\n",
    "x2_train,x2_test,y2_train,y2_test=train_test_split(true_questions,true_question_classes)\n",
    "y2_train=tf.one_hot(y2_train,depth=class_num+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_head(x):\n",
    "    x=Dense(300)(x)\n",
    "    x=Activation(LeakyReLU(0.2))(x)\n",
    "    x=Reshape((10,10,3))(x)\n",
    "    x=Conv2D(32,(3,3),padding='same')(x)\n",
    "    x=Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=Flatten()(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_input=Input(shape=(300,))\n",
    "question_input=Input(shape=(300,))\n",
    "\n",
    "document_output=search_head(tf.expand_dims(document_input,1))\n",
    "question_output=search_head(tf.expand_dims(question_input,1))\n",
    "\n",
    "x=concatenate((document_output,question_output),axis=1)\n",
    "x=Dense(256)(x)\n",
    "x=Activation(LeakyReLU(0.2))(x)\n",
    "\n",
    "x=Dense(class_num+1,activation='softmax')(x)\n",
    "\n",
    "model=Model(inputs=[document_input,question_input],outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_2 (TFOpLambda)   (None, 1, 300)       0           input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_3 (TFOpLambda)   (None, 1, 300)       0           input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 1, 300)       90300       tf.expand_dims_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 1, 300)       90300       tf.expand_dims_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1, 300)       0           dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 1, 300)       0           dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 10, 3)    0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 10, 3)    0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 10, 10, 32)   896         reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 32)   896         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 64)   18496       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 10, 64)   18496       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6400)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6400)         0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 12800)        0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 256)          3277056     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 256)          0           dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 11)           2827        activation_62[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,499,267\n",
      "Trainable params: 3,499,267\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "142/142 [==============================] - 6s 7ms/step - loss: 321.1206 - categorical_crossentropy: 321.1206\n",
      "Epoch 2/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 17320.4709 - categorical_crossentropy: 17320.4709\n",
      "Epoch 3/15\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 217406.6017 - categorical_crossentropy: 217406.6017\n",
      "Epoch 4/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 827465.1746 - categorical_crossentropy: 827465.1746: 0s - loss: 723005.6580 - categorical_crossen\n",
      "Epoch 5/15\n",
      "142/142 [==============================] - 1s 7ms/step - loss: 2221594.8121 - categorical_crossentropy: 2221594.8121\n",
      "Epoch 6/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 5405401.8837 - categorical_crossentropy: 5405401.8837\n",
      "Epoch 7/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 12379370.8007 - categorical_crossentropy: 12379370.8007\n",
      "Epoch 8/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 24723313.4615 - categorical_crossentropy: 24723313.4615\n",
      "Epoch 9/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 39386830.2517 - categorical_crossentropy: 39386830.2517\n",
      "Epoch 10/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 56078594.0979 - categorical_crossentropy: 56078594.0979\n",
      "Epoch 11/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 107053040.8671 - categorical_crossentropy: 107053040.8671\n",
      "Epoch 12/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 123337759.6364 - categorical_crossentropy: 123337759.6364\n",
      "Epoch 13/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 196337353.3986 - categorical_crossentropy: 196337353.3986\n",
      "Epoch 14/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 261239268.2517 - categorical_crossentropy: 261239268.2517\n",
      "Epoch 15/15\n",
      "142/142 [==============================] - 1s 6ms/step - loss: 457610143.8881 - categorical_crossentropy: 457610143.8881\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='RMSprop',metrics=['categorical_crossentropy'])\n",
    "history=model.fit([x1_train,x2_train],y1_train,verbose=1,batch_size=1,epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('сложнейший', 0.7793360948562622),\n",
       " ('трудный', 0.766022801399231),\n",
       " ('несложный', 0.7286560535430908),\n",
       " ('трудоемкий', 0.7172977328300476),\n",
       " ('запутанный', 0.6913840770721436),\n",
       " ('специфичный', 0.687846839427948),\n",
       " ('важный', 0.6857823729515076),\n",
       " ('тривиальный', 0.6841895580291748),\n",
       " ('интересный', 0.6826520562171936),\n",
       " ('непростой', 0.680992066860199)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.most_similar('сложный')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 300)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "[Reference](https://medium.com/swlh/fine-tuning-bert-for-text-classification-and-question-answering-using-tensorflow-framework-4d09daeb3330#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjFiZjhhODRkM2VjZDc3ZTlmMmFkNWYwNmZmZDI2MDcwMWRkMDZkOTAiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MjU5MDYxNDIsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNjU4MDUxNjE5NzU3NTk0MTk2NCIsImhkIjoibWllbS5oc2UucnUiLCJlbWFpbCI6ImRna2FncmFtYW55YW5AbWllbS5oc2UucnUiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiYXpwIjoiMjE2Mjk2MDM1ODM0LWsxazZxZTA2MHMydHAyYTJqYW00bGpkY21zMDBzdHRnLmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tIiwibmFtZSI6ItCU0LDQstC40LQg0JrQsNCz0YDQsNC80LDQvdGP0L0iLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EtL0FPaDE0R2hGdEZGSkZMaDlyUFV0QXdZLXlyZWlRczJObjEyQ2xpc3hmX3hQPXM5Ni1jIiwiZ2l2ZW5fbmFtZSI6ItCU0LDQstC40LQiLCJmYW1pbHlfbmFtZSI6ItCa0LDQs9GA0LDQvNCw0L3Rj9C9IiwiaWF0IjoxNjI1OTA2NDQyLCJleHAiOjE2MjU5MTAwNDIsImp0aSI6IjhiYmVjYmRjYWRiZTAyZDZkNjQ1MTMxY2Q2NzJhZTI4MWViMTdkNWYifQ.LRr773uwpuGgpYnO7WsltRMVbC3JdFg7DBIlPtnLhN11OpKyNZ5X3y2ZGLx72_tJaSXZS52xdLcEsLuM4Tk1Ta_4ifnuAMkkeJMYJct0DpJOqXGYWS9S2atl8JLvbQaLyNrseNHneLtzRgtj--Htk1Lq0red-VmGxO849tzhKfjfQDPw-PsKxnhKMxHoEHJs91z-djL_L8ATQ6p86TcSWzWGsi4Ya69TmkMiRw-W2eMaZjN11gjSXUCnJKUUC122fluOmDzsGnUbtpoSGD-86mTa368FTFLbQSC7M8SGiZKo_pIZCcKrGjBQM-bJFAMs3-I8J7nM6782Vlh_CZiBew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/distilrubert-base-cased-conversational were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/distilrubert-base-cased-conversational\")\n",
    "model = AutoModel.from_pretrained(\"DeepPavlov/distilrubert-base-cased-conversational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()\n",
    "\n",
    "print(embed_bert_cls('привет мир', model, tokenizer).shape)\n",
    "# (312,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=tokenizer(['Хочу кредитную карту','Как взять кредит','Хочу взять кредит наличными'],padding=True)\n",
    "\n",
    "text=['Хочу кредитную карту','Хочу взять кредит наличными',\n",
    "      'Кредитование','Страхование','Инвестиции']\n",
    "tokens_vectors=get_embedding(ft_model,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  101,  9620, 77624,  5538,   102,     0,     1,     1,     1,\n",
       "             1,     1,     0],\n",
       "        [  101,  1235,  3715,  7916,   102,     0,     1,     1,     1,\n",
       "             1,     1,     0],\n",
       "        [  101,  9620,  3715,  7916, 49392,   102,     1,     1,     1,\n",
       "             1,     1,     1]])]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks=np.array(tokens['attention_mask'])\n",
    "ids=np.array(tokens['input_ids'])\n",
    "data=[np.concatenate([ids,masks],axis=1)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-455a3b771d60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpt_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m             \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "pt_outputs = model(data, output_hidden_states=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.49685953, 0.1073186 ],\n",
       "       [0.49685953, 1.        , 0.20703129],\n",
       "       [0.1073186 , 0.20703129, 1.        ]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.pairwise.cosine_similarity(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (256) must match the existing size (3) at non-singleton dimension 3.  Target sizes: [1, 3, 256, 256].  Tensor sizes: [1, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-2906cd1ded3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchsummaryX\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0march\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torchsummaryX\\torchsummaryX.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m         return self.transformer(\n\u001b[0;32m    482\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mseq_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mposition_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (max_seq_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mposition_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mword_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (256) must match the existing size (3) at non-singleton dimension 3.  Target sizes: [1, 3, 256, 256].  Tensor sizes: [1, 3]"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "arch = summary(model, torch.rand((1, 3, 256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(context,questions,answer):\n",
    "    \n",
    "    t_context = tokenizer(context,padding=True)\n",
    "    t_questions = tokenizer(questions,padding=True)\n",
    "        \n",
    "    # create inputs as usual\n",
    "    input_ids = t_context['input_ids'] + t_questions['input_ids']\n",
    "    token_type_ids = [0] * len(t_context['input_ids']) + t_questions['attention_mask']\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "\n",
    "    return input_ids,token_type_ids,attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=list(faq1[:,1].reshape((1,-1))[0])\n",
    "context=\" \".join(questions)\n",
    "input_ids,token_type_ids,attention_mask=preprocess(context,questions,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7289"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(context.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string=questions[0].replace('\\n','')\n",
    "len(string.replace('/','').split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, question, context, start_char_idx=None, answer_text=None, all_answers=None):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = answer_text\n",
    "        self.all_answers = all_answers\n",
    "        self.skip = False\n",
    "        self.start_token_idx = -1\n",
    "        self.end_token_idx = -1\n",
    "\n",
    "    def preprocess(self):\n",
    "        # clean context and question\n",
    "        context = \" \".join(str(self.context).split())\n",
    "        question = \" \".join(str(self.question).split())\n",
    "        # tokenize context and question\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "        \n",
    "        # if this is validation or training sample, preprocess answer\n",
    "        if self.answer_text is not None:\n",
    "            answer = \" \".join(str(self.answer_text).split())\n",
    "            # check if end character index is in the context\n",
    "            end_char_idx = self.start_char_idx + len(answer)\n",
    "            if end_char_idx >= len(context):\n",
    "                self.skip = True\n",
    "                return\n",
    "            # mark all the character indexes in context that are also in answer     \n",
    "            is_char_in_ans = [0] * len(context)\n",
    "            for idx in range(self.start_char_idx, end_char_idx):\n",
    "                is_char_in_ans[idx] = 1\n",
    "            ans_token_idx = []\n",
    "            # find all the tokens that are in the answers\n",
    "            for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
    "                if sum(is_char_in_ans[start:end]) > 0:\n",
    "                    ans_token_idx.append(idx)\n",
    "            if len(ans_token_idx) == 0:\n",
    "                self.skip = True\n",
    "                return\n",
    "            # get start and end token indexes\n",
    "            self.start_token_idx = ans_token_idx[0]\n",
    "            self.end_token_idx = ans_token_idx[-1]\n",
    "        # create inputs as usual\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        # add padding if necessary\n",
    "        if padding_length > 0:\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:\n",
    "            self.skip = True\n",
    "            return\n",
    "        self.input_word_ids = input_ids\n",
    "        self.input_type_ids = token_type_ids\n",
    "        self.input_mask = attention_mask\n",
    "        self.context_token_to_char = tokenized_context.offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_squad_examples(raw_data):\n",
    "    squad_examples = []\n",
    "    for item in raw_data[\"data\"]:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            context = para[\"context\"]\n",
    "            for qa in para[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                if \"answers\" in qa:\n",
    "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                    all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
    "                    start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
    "                    squad_eg = Sample(question, context, start_char_idx, answer_text, all_answers)\n",
    "                else:\n",
    "                    squad_eg = Sample(question, context)\n",
    "                squad_eg.preprocess()\n",
    "                squad_examples.append(squad_eg)\n",
    "    return squad_examples\n",
    "\n",
    "\n",
    "def create_inputs_targets(squad_examples):\n",
    "    dataset_dict = {\n",
    "        \"input_word_ids\": [],\n",
    "        \"input_type_ids\": [],\n",
    "        \"input_mask\": [],\n",
    "        \"start_token_idx\": [],\n",
    "        \"end_token_idx\": [],\n",
    "    }\n",
    "    for item in squad_examples:\n",
    "        if item.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                dataset_dict[key].append(getattr(item, key))\n",
    "    for key in dataset_dict:\n",
    "        dataset_dict[key] = np.array(dataset_dict[key])\n",
    "    x = [dataset_dict[\"input_word_ids\"],\n",
    "         dataset_dict[\"input_mask\"],\n",
    "         dataset_dict[\"input_type_ids\"]]\n",
    "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def normalize_text(self, text):\n",
    "        # convert to lower case\n",
    "        text = text.lower()\n",
    "        # remove redundant whitespaces\n",
    "        text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n",
    "        # remove articles\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        text = re.sub(regex, \" \", text)\n",
    "        text = \" \".join(text.split())\n",
    "        return text\n",
    "\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # get the offsets of the first and last tokens of predicted answers\n",
    "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
    "        count = 0\n",
    "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
    "        # for every pair of offsets\n",
    "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "            # take the required Sample object with the ground-truth answers in it\n",
    "            squad_eg = eval_examples_no_skip[idx]\n",
    "            # use offsets to get back the span of text corresponding to\n",
    "            # our predicted first and last tokens\n",
    "            offsets = squad_eg.context_token_to_char\n",
    "            start = np.argmax(start)\n",
    "            end = np.argmax(end)\n",
    "            if start >= len(offsets):\n",
    "                continue\n",
    "            pred_char_start = offsets[start][0]\n",
    "            if end < len(offsets):\n",
    "                pred_char_end = offsets[end][1]\n",
    "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
    "            else:\n",
    "                pred_ans = squad_eg.context[pred_char_start:]\n",
    "            normalized_pred_ans = self.normalize_text(pred_ans)\n",
    "            # clean the real answers\n",
    "            normalized_true_ans = [self.normalize_text(_) for _ in squad_eg.all_answers]\n",
    "            # check if the predicted answer is in an array of the ground-truth answers\n",
    "            if normalized_pred_ans in normalized_true_ans:\n",
    "                count += 1\n",
    "        acc = count / len(self.y_eval[0])\n",
    "        print(f\"\\nepoch={epoch + 1}, exact match score={acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = keras.utils.get_file(\"train.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\")\n",
    "eval_path = keras.utils.get_file(\"eval.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\")\n",
    "\n",
    "with open(train_path) as f:\n",
    "    raw_train_data = json.load(f)\n",
    "    \n",
    "with open(eval_path) as f:\n",
    "    raw_eval_data = json.load(f)\n",
    "\n",
    "max_seq_length = 384\n",
    "\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_mask')\n",
    "input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertWordPieceTokenizer(vocab=vocab_file, lowercase=True)\n",
    "train_squad_examples = create_squad_examples(raw_train_data)\n",
    "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")\n",
    "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
    "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
    "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n",
    "start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(sequence_output)\n",
    "start_logits = layers.Flatten()(start_logits)\n",
    "end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(sequence_output)\n",
    "end_logits = layers.Flatten()(end_logits)\n",
    "start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
    "end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
    "model = keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=[start_probs, end_probs])\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "model.compile(optimizer=optimizer, loss=[loss, loss])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=8, callbacks=[ValidationCallback(x_eval, y_eval)])\n",
    "model.save_weights(\"./weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"data\":\n",
    "    [\n",
    "        {\"title\": \"Project Apollo\",\n",
    "         \"paragraphs\": [\n",
    "             {\n",
    "                 \"context\": \"The Apollo program, also known as Project Apollo, was the third United States human \"\n",
    "                            \"spaceflight program carried out by the National Aeronautics and Space Administration (\"\n",
    "                            \"NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First \"\n",
    "                            \"conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to \"\n",
    "                            \"follow the one-man Project Mercury which put the first Americans in space, Apollo was \"\n",
    "                            \"later dedicated to President John F. Kennedy's national goal of landing a man on the \"\n",
    "                            \"Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in \"\n",
    "                            \"a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project \"\n",
    "                            \"Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, \"\n",
    "                            \"and was supported by the two man Gemini program which ran concurrently with it from 1962 \"\n",
    "                            \"to 1966. Gemini missions developed some of the space travel techniques that were \"\n",
    "                            \"necessary for the success of the Apollo missions. Apollo used Saturn family rockets as \"\n",
    "                            \"launch vehicles. Apollo/Saturn vehicles were also used for an Apollo Applications \"\n",
    "                            \"Program, which consisted of Skylab, a space station that supported three manned missions \"\n",
    "                            \"in 1973-74, and the Apollo-Soyuz Test Project, a joint Earth orbit mission with the \"\n",
    "                            \"Soviet Union in 1975.\",\n",
    "                 \"qas\": [\n",
    "                     {\"question\": \"What project put the first Americans into space?\",\n",
    "                      \"id\": \"Q1\"\n",
    "                      },\n",
    "                     {\"question\": \"What program was created to carry out these projects and missions?\",\n",
    "                      \"id\": \"Q2\"\n",
    "                      },\n",
    "                     {\"question\": \"What year did the first manned Apollo flight occur?\",\n",
    "                      \"id\": \"Q3\"\n",
    "                      },\n",
    "                     {\"question\": \"What President is credited with the original notion of putting Americans in space?\",\n",
    "                      \"id\": \"Q4\"\n",
    "                      },\n",
    "                     {\"question\": \"Who did the U.S. collaborate with on an Earth orbit mission in 1975?\",\n",
    "                      \"id\": \"Q5\"\n",
    "                      },\n",
    "                     {\"question\": \"How long did Project Apollo run?\",\n",
    "                      \"id\": \"Q6\"\n",
    "                      },\n",
    "                     {\"question\": \"What program helped develop space travel techniques that Project Apollo used?\",\n",
    "                      \"id\": \"Q7\"\n",
    "                      },\n",
    "                     {\"question\": \"What space station supported three manned missions in 1973-1974?\",\n",
    "                      \"id\": \"Q8\"\n",
    "                      }\n",
    "                 ]}]}]}\n",
    "\n",
    "test_samples = create_squad_examples(data)\n",
    "x_test, _ = create_inputs_targets(test_samples)\n",
    "pred_start, pred_end = model.predict(x_test)\n",
    "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "    test_sample = test_samples[idx]\n",
    "    offsets = test_sample.context_token_to_char\n",
    "    start = np.argmax(start)\n",
    "    end = np.argmax(end)\n",
    "    pred_ans = None\n",
    "    if start >= len(offsets):\n",
    "        continue\n",
    "    pred_char_start = offsets[start][0]\n",
    "    if end < len(offsets):\n",
    "        pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
    "    else:\n",
    "        pred_ans = test_sample.context[pred_char_start:]\n",
    "    print(\"Q: \" + test_sample.question)\n",
    "    print(\"A: \" + pred_ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
