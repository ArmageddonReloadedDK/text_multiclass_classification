{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from numpy import genfromtxt\n",
    "import re\n",
    "from scipy import spatial\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn import cluster\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class SearchEngine():\n",
    "    def __init__(self, faq, system_faq, services_faq, sbert_path=False):\n",
    "        self.faq = self.faq_normilize(faq)\n",
    "        self.system_faq = self.faq_normilize(system_faq)\n",
    "        self.services_faq = self.faq_normilize(services_faq)\n",
    "        if sbert_path:\n",
    "            start = time.time()\n",
    "\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            self.sbert_model = AutoModel.from_pretrained(sbert_path)\n",
    "            self.sbert_model.to(self.device)\n",
    "            self.sbert_tokenizer = AutoTokenizer.from_pretrained(sbert_path)\n",
    "            self.faq_embs = np.array([self.sent_vectorizer(sent) for sent in self.faq[:, 0]])\n",
    "            self.system_faq_embs = np.array([self.sent_vectorizer(sent) for sent in self.system_faq[:, 0]])\n",
    "            self.services_faq_embs = np.array([self.sent_vectorizer(sent) for sent in self.services_faq[:, 0]])\n",
    "\n",
    "            end = time.time()\n",
    "            self.MorphAnalyzer = pymorphy2.MorphAnalyzer()\n",
    "            print('Sbert model and faq successfully loaded\\nPassed time:', round(end - start, 2), 's')\n",
    "\n",
    "    def faq_normilize(self, faq):\n",
    "        \"\"\"\n",
    "        :param self:\n",
    "        :param faq: ndaarray str shape (n,2)\n",
    "        :return: ndaarray str shape (n,2)\n",
    "        \"\"\"\n",
    "\n",
    "        copy_faq = faq.copy()\n",
    "        for i in range(len(faq)):\n",
    "            question = copy_faq[i, 0]\n",
    "            question = question.lower()\n",
    "            question = question.replace('/', ' или ')\n",
    "            reg = re.compile('[^а-яА-Я0-9% ]')\n",
    "            question = reg.sub('', question)\n",
    "            copy_faq[i, 0] = question\n",
    "\n",
    "        return copy_faq\n",
    "\n",
    "    def sent_vectorizer(self, sentence):\n",
    "        encoded_input = self.sbert_tokenizer(sentence,\n",
    "                                             padding=True,\n",
    "                                             truncation=True,\n",
    "                                             max_length=24,\n",
    "                                             return_tensors='pt').to(self.device)\n",
    "\n",
    "        #     with torch.no_grad():\n",
    "        model_output = self.sbert_model(**encoded_input)\n",
    "\n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        sentence_embedding = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embedding = np.squeeze(sentence_embedding)\n",
    "\n",
    "        return sentence_embedding.cpu().data.numpy()\n",
    "\n",
    "    def mean_pooling(cls, model_output, attention_mask):\n",
    "        #Mean Pooling - Take attention mask into account for correct averaging\n",
    "        token_embeddings = model_output[0]  #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    def search_faq(self, question, eps, minimal_score, type='faq', verbose=False):\n",
    "        '''\n",
    "        :param question: str\n",
    "        :param eps: scalar float [0,1]\n",
    "        :param minimal_score: scalar float [0,1]\n",
    "        :return: ndarray shape (n,2); [[index1, score1], [index2, score2]..]\n",
    "        '''\n",
    "\n",
    "        question_emb = self.sent_vectorizer(question)\n",
    "        if type == 'faq':\n",
    "            faq = self.faq\n",
    "            faq_embs = self.faq_embs\n",
    "        elif type == 'system':\n",
    "            faq = self.system_faq\n",
    "            faq_embs = self.system_faq_embs\n",
    "        elif type == 'services':\n",
    "            faq = self.services_faq\n",
    "            faq_embs = self.system_faq_embs\n",
    "\n",
    "        score = np.zeros((faq.shape[0], 1))\n",
    "\n",
    "        # обход всего датасета эмбеддингов вопросов\n",
    "        for i, faq_emb in enumerate(faq_embs):\n",
    "            score[i, 0] = 1 - spatial.distance.cosine(faq_emb, question_emb)\n",
    "\n",
    "        # индексы эмбеддингов для сортировки\n",
    "        indeces = np.arange(0, faq.shape[0]).reshape((-1, 1))\n",
    "\n",
    "        # сортировка\n",
    "        faq_logits = np.concatenate([indeces, score], axis=1)\n",
    "        faq_logits = faq_logits[faq_logits[:, 1].argsort()[::-1]]\n",
    "\n",
    "        # выислиение количества индексов для вывода\n",
    "        max_score = faq_logits[0, 1]\n",
    "        display_num = 0\n",
    "\n",
    "        for scr in faq_logits[:, 1]:\n",
    "            if max_score - scr < eps and scr > minimal_score:\n",
    "                display_num += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if verbose:\n",
    "            print('Question: ', question)\n",
    "            print('---------------------')\n",
    "            questions_indeces = faq_logits[:, 0].astype('int64')\n",
    "            questions = faq[questions_indeces][:display_num, 0]\n",
    "            for i, faq_question in enumerate(questions):\n",
    "                print('index ', faq_logits[i, 0], ' score ', faq_logits[i, 1], faq_question)\n",
    "\n",
    "        return faq_logits[:display_num]\n",
    "\n",
    "    def clean_faq(self, faq_logits, verbose=False):\n",
    "        \"\"\"\n",
    "        :param self:\n",
    "        :param faq_logits: ndarray shape (n,2); [[index1, score1], [index2, score2]..]\n",
    "        :param verbose: bool\n",
    "        :param plot: bool\n",
    "        :return: ndarray shape (n,), [index1,index2,index3..]\n",
    "        \"\"\"\n",
    "\n",
    "        questions_indeces = faq_logits[:, 0].astype('int64')\n",
    "\n",
    "        n_clusters = 2\n",
    "        if faq_logits.shape[0] > n_clusters:\n",
    "\n",
    "            # кластеризация найденных вопросов\n",
    "            clustering = cluster.KMeans(n_clusters)\n",
    "            raw_questions = np.concatenate([self.faq_embs[questions_indeces]])\n",
    "            db_clusters = clustering.fit_predict(raw_questions)\n",
    "\n",
    "            # вычисление среднего значения точности кластеров\n",
    "            clusters_score = np.zeros((n_clusters))\n",
    "            clusters_size = np.zeros((n_clusters))\n",
    "\n",
    "            for i, logit in enumerate(faq_logits):\n",
    "                index = db_clusters[i]\n",
    "                clusters_score[index] += logit[1]\n",
    "                clusters_size[index] += 1\n",
    "\n",
    "            clusters_mean_score = clusters_score / clusters_size\n",
    "\n",
    "            # вывод кластеризированных вопросов\n",
    "            max_score_val = clusters_mean_score.max(axis=0)\n",
    "            max_score_index = np.where(clusters_mean_score == max_score_val)[0]\n",
    "\n",
    "            true_faq_lofits = faq_logits[np.where(db_clusters == max_score_index)]\n",
    "            true_questions_indeces = true_faq_lofits[:, 0].astype('int64').reshape((1, -1))\n",
    "\n",
    "            if verbose:\n",
    "                print('\\nCleaned questions')\n",
    "                print('---------------------')\n",
    "                true_questions = self.faq[true_questions_indeces][0, :, 0]\n",
    "                for i, faq_question in enumerate(true_questions):\n",
    "                    print('index ', faq_logits[i, 0], ' score ', faq_logits[i, 1], faq_question)\n",
    "\n",
    "            return true_questions_indeces.astype('int32')[0]\n",
    "        else:\n",
    "            return questions_indeces.reshape((1, -1)).astype('int32')\n",
    "\n",
    "    def questions_diffs(self, questions_indeces, min_score, max_score, verbose=False):\n",
    "        \"\"\"\n",
    "        :param self:\n",
    "        :param questions_indeces: list shape (n,)\n",
    "        :param min_score: scalar float [0,1]\n",
    "        :param max_score: scalar float [0,1]\n",
    "        :param verbose: bool\n",
    "        :return: list [[str1,index1],[str2,index2]..]\n",
    "        \"\"\"\n",
    "\n",
    "        questions = self.faq[questions_indeces][:, 0]\n",
    "\n",
    "        words_pool_embs = []\n",
    "        questions_words_embs = []\n",
    "        questions_words = []\n",
    "\n",
    "        for question in questions:\n",
    "            words = question.split()\n",
    "            questions_words.append(words)\n",
    "            words_embs = [self.sent_vectorizer(word) for word in words]\n",
    "            questions_words_embs.append(words_embs)\n",
    "\n",
    "            words_pool_embs = words_pool_embs + words_embs\n",
    "\n",
    "        common_words_indx = []\n",
    "\n",
    "        # поиск повторяющихся слов\n",
    "        for i, word1 in enumerate(words_pool_embs):\n",
    "            word_score = 0\n",
    "\n",
    "            for j, word2 in enumerate(words_pool_embs):\n",
    "                if i != j:\n",
    "                    score = 1 - spatial.distance.cosine(word1, word2)\n",
    "                    if score > word_score:\n",
    "                        word_score = score\n",
    "\n",
    "            if word_score > min_score:\n",
    "                common_words_indx.append(i)\n",
    "\n",
    "        words_pool_embs = np.array(words_pool_embs)\n",
    "        common_words_embs = words_pool_embs[common_words_indx]\n",
    "        questions_diffs_eye = []\n",
    "\n",
    "        # повторный проход по вопросам\n",
    "        for i, question in enumerate(questions_words_embs):\n",
    "            questions_diffs_eye.append([])\n",
    "\n",
    "            for word1 in question:\n",
    "                word_score = 0\n",
    "                for word2 in common_words_embs:\n",
    "                    score = 1 - spatial.distance.cosine(word1, word2)\n",
    "                    if score > word_score:\n",
    "                        word_score = score\n",
    "\n",
    "                if word_score > max_score:\n",
    "                    # если слово повтторяющееся\n",
    "                    questions_diffs_eye[i].append(0)\n",
    "                else:\n",
    "                    # если слово уникальное\n",
    "                    questions_diffs_eye[i].append(1)\n",
    "\n",
    "        if verbose:\n",
    "            print('\\ndiff indeces ', questions_diffs_eye)\n",
    "            print('-----------')\n",
    "        diff_words = []\n",
    "\n",
    "        for i, question_eye in enumerate(questions_diffs_eye):\n",
    "            question_eye = np.array(question_eye)\n",
    "            indeces = np.where(question_eye == 1)[0]\n",
    "            #   print('indeces ',indeces)\n",
    "\n",
    "            start = indeces[0]\n",
    "            end = indeces[-1] + 1\n",
    "            # изменяя start и stop можно выделят разные отличающиеся части вопросов\n",
    "            diff_words.append(questions_words[i][:])\n",
    "\n",
    "        diffs = [[\" \".join(words)] for words in diff_words]\n",
    "        for i, diff in enumerate(diffs):\n",
    "            diff.append(questions_indeces[i])\n",
    "\n",
    "        return diffs\n",
    "\n",
    "    def compare_answer_diffs(self, diffs, answer):\n",
    "        \"\"\"\n",
    "        :param self:\n",
    "        :param diffs: list [[str1,index1],[str2,index2]..]\n",
    "        :param answer: str\n",
    "        :return: tuple shape (2,), (question_index,score)\n",
    "        \"\"\"\n",
    "        answer_emb = self.sent_vectorizer(answer)\n",
    "        diffs_embs = [self.sent_vectorizer(diff[0]) for diff in diffs]\n",
    "\n",
    "        index = 0\n",
    "        score = 0\n",
    "\n",
    "        for i, diff_emb in enumerate(diffs_embs):\n",
    "            diff_score = 1 - spatial.distance.cosine(diff_emb, answer_emb)\n",
    "            if score < diff_score:\n",
    "                index = i\n",
    "                score = diff_score\n",
    "\n",
    "        true_question_index = diffs[index][1]\n",
    "\n",
    "        return true_question_index, score\n",
    "\n",
    "    def create_system_question(self, diffs):\n",
    "        \"\"\"\n",
    "        :param self:\n",
    "        :param diffs: list [[str1,index1],[str2,index2]..]\n",
    "        :return: str\n",
    "        \"\"\"\n",
    "        morph = self.MorphAnalyzer\n",
    "        system_question = 'Вас интересует '\n",
    "        n = len(diffs)\n",
    "\n",
    "        connectors = []\n",
    "\n",
    "        if n == 2:\n",
    "            connectors = ['или ', '?']\n",
    "        elif n == 3:\n",
    "            connectors = [', ', ' или ', '?']\n",
    "\n",
    "        for i, diff in enumerate(diffs):\n",
    "            diff_words = diff[0].split()\n",
    "            # print('diff ', diff)\n",
    "            q = ''\n",
    "            for word in diff_words:\n",
    "                p = morph.parse(word)[0]\n",
    "                if p.tag.POS == 'NOUN':\n",
    "                    q += word + ' '\n",
    "                    #q += p.normal_form + ' '\n",
    "                else:\n",
    "                    q += word + ' '\n",
    "\n",
    "            system_question += q + connectors[i]\n",
    "\n",
    "        return system_question"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbert model and faq successfully loaded\n",
      "Passed time: 8.76 s\n"
     ]
    }
   ],
   "source": [
    "sbert_path = \"models/sbert_large_mt_nlu_ru\"\n",
    "faq = genfromtxt('faq.csv', delimiter=',', encoding='utf-8', dtype=str, usecols=(0, 1))[1:]\n",
    "\n",
    "engine = SearchEngine(faq, faq, faq, sbert_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "#question = 'льгота  от расхода'\n",
    "# question='Как будут осуществляться начисления если счетчик сломается'\n",
    "question = 'Как оформить льготу'\n",
    "additional_answer = 'в москве'\n",
    "\n",
    "eps = 0.15\n",
    "minimal_score = 0.7\n",
    "\n",
    "# ищем похожие вопросы в датасете\n",
    "# если больше 1 совпадения, кластеризуем и выбираем кластер с наибольшей точностью\n",
    "dirty_system_indeces = engine.search_faq(question, eps, minimal_score,type='system')\n",
    "\n",
    "if len(dirty_system_indeces)==0:\n",
    "\n",
    "    dirty_services_indeces = engine.search_faq(question, eps, minimal_score,type='service')\n",
    "    if len(dirty_services_indeces)==0:\n",
    "        \n",
    "        dirty_indeces = engine.search_faq(question, eps, minimal_score,type='faq')\n",
    "        cleaned_indeces = engine.clean_faq(dirty_indeces, False)\n",
    "\n",
    "        # если после кластеризации больше 1 совпадения\n",
    "        if len(cleaned_indeces) > 1:\n",
    "\n",
    "            # ищем отличающиеся в вопросах слова\n",
    "            diffs = engine.questions_diffs(cleaned_indeces, min_score=0.8, max_score=0.8, verbose=False)\n",
    "\n",
    "            # формируем уточняющий вопрос\n",
    "            system_question = engine.create_system_question(diffs)\n",
    "\n",
    "            print(system_question)\n",
    "\n",
    "            flag = True\n",
    "            # сравниваем ответ пользователя и отличающиеся части вопросов\n",
    "            while flag:\n",
    "                true_question_index, score = engine.compare_answer_diffs(diffs, question + ' ' + additional_answer)\n",
    "                if score > 0.6:\n",
    "                    flag = False\n",
    "                    question, answer = engine.faq[true_question_index]\n",
    "                    print(true_question_index, score, question)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torch",
   "language": "python",
   "display_name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}