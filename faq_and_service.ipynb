{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from matplotlib.colors import ListedColormap\n",
    "from numpy.random import choice\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "import re\n",
    "\n",
    "from gensim.models import FastText, KeyedVectors, fasttext\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel, AutoModel\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cluster\n",
    "\n",
    "import seaborn as sns\n",
    "import umap\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models/sbert_large_mt_nlu_ru/4'\n",
    "model = TFAutoModel.from_pretrained(path)\n",
    "#model = AutoModel.from_pretrained(path)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "my_data = genfromtxt('faq.csv', delimiter=',', encoding='utf-8', dtype=str, usecols=(0, 1))[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ft_model = fasttext.FastTextKeyedVectors.load('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_sentence_ft(self, sentence):\n",
    "    txt = sentence.split()\n",
    "    val = 0\n",
    "    for word in txt:\n",
    "        val += self.ft_model[word]\n",
    "\n",
    "    return val / len(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine():\n",
    "    def __init__(self, faq, sbert_path=False):\n",
    "        self.faq = self.faq_normilize(faq)\n",
    "        if sbert_path:\n",
    "            start = time.time()\n",
    "\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            self.sbert_model = AutoModel.from_pretrained(sbert_path)\n",
    "            self.sbert_model.to(self.device)\n",
    "            self.sbert_tokenizer = AutoTokenizer.from_pretrained(sbert_path)\n",
    "            self.faq_embs = np.array([self.sent_vectorizer(sent) for sent in self.faq[:, 0]])\n",
    "\n",
    "            end = time.time()\n",
    "            self.MorphAnalyzer = pymorphy2.MorphAnalyzer()\n",
    "            print('Sbert model and faq successfully loaded\\nPassed time:', round(end - start, 2), 's')\n",
    "\n",
    "    def faq_normilize(self, faq):\n",
    "        \"\"\"\n",
    "        :param self:\n",
    "        :param faq: ndaarray str shape (n,2)\n",
    "        :return: ndaarray str shape (n,2)\n",
    "        \"\"\"\n",
    "\n",
    "        copy_faq = faq.copy()\n",
    "        for i in range(len(faq)):\n",
    "            question = copy_faq[i, 0]\n",
    "            question = question.lower()\n",
    "            question = question.replace('/', ' или ')\n",
    "            reg = re.compile('[^а-яА-Я0-9% ]')\n",
    "            question = reg.sub('', question)\n",
    "            copy_faq[i, 0] = question\n",
    "\n",
    "        return copy_faq\n",
    "\n",
    "    def sent_vectorizer(self, sentence):\n",
    "        encoded_input = self.sbert_tokenizer(sentence,\n",
    "                                             padding=True,\n",
    "                                             truncation=True,\n",
    "                                             max_length=24,\n",
    "                                             return_tensors='pt').to(self.device)\n",
    "\n",
    "        #     with torch.no_grad():\n",
    "        model_output = self.sbert_model(**encoded_input)\n",
    "\n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        sentence_embedding = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embedding = np.squeeze(sentence_embedding)\n",
    "\n",
    "        return sentence_embedding.cpu().data.numpy()\n",
    "\n",
    "    def mean_pooling(cls, model_output, attention_mask):\n",
    "        #Mean Pooling - Take attention mask into account for correct averaging\n",
    "        token_embeddings = model_output[0]  #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbert model and faq successfully loaded\n",
      "Passed time: 12.0 s\n"
     ]
    }
   ],
   "source": [
    "sbert_path = \"models/sbert_large_mt_nlu_ru\"\n",
    "faq = genfromtxt('faq.csv', delimiter=',', encoding='utf-8', dtype=str, usecols=(0, 1))[1:]\n",
    "\n",
    "engine = SearchEngine(faq, sbert_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def search_faq(self, question, eps, minimal_score, verbose=False):\n",
    "    '''\n",
    "    :param question: str\n",
    "    :param eps: scalar float [0,1]\n",
    "    :param minimal_score: scalar float [0,1]\n",
    "    :return: ndarray shape (n,2); [[index1, score1], [index2, score2]..]\n",
    "    '''\n",
    "\n",
    "    question_emb = self.sent_vectorizer(question)\n",
    "    score = np.zeros((self.faq.shape[0], 1))\n",
    "\n",
    "    # обход всего датасета эмбеддингов вопросов\n",
    "    for i, faq_emb in enumerate(self.faq_embs):\n",
    "        score[i, 0] = 1 - spatial.distance.cosine(faq_emb, question_emb)\n",
    "\n",
    "    # индексы эмбеддингов для сортировки\n",
    "    indeces = np.arange(0, self.faq.shape[0]).reshape((-1, 1))\n",
    "\n",
    "    # сортировка\n",
    "    faq_logits = np.concatenate([indeces, score], axis=1)\n",
    "    faq_logits = faq_logits[faq_logits[:, 1].argsort()[::-1]]\n",
    "\n",
    "    # выислиение количества индексов для вывода\n",
    "    max_score = faq_logits[0, 1]\n",
    "    display_num = 0\n",
    "\n",
    "    for scr in faq_logits[:, 1]:\n",
    "        if max_score - scr < eps and scr > minimal_score:\n",
    "            display_num += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print('Question: ', question)\n",
    "        print('---------------------')\n",
    "        questions_indeces = faq_logits[:, 0].astype('int64')\n",
    "        questions = self.faq[questions_indeces][:display_num, 0]\n",
    "        for i, faq_question in enumerate(questions):\n",
    "            print('index ', faq_logits[i, 0], ' score ', faq_logits[i, 1], faq_question)\n",
    "\n",
    "    return faq_logits[:display_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_faq(self, faq_logits, verbose=False, plot=False):\n",
    "    \"\"\"\n",
    "    :param self:\n",
    "    :param faq_logits: ndarray shape (n,2); [[index1, score1], [index2, score2]..]\n",
    "    :param verbose: bool\n",
    "    :param plot: bool\n",
    "    :return: ndarray shape (n,), [index1,index2,index3..]\n",
    "    \"\"\"\n",
    "\n",
    "    questions_indeces = faq_logits[:, 0].astype('int64')\n",
    "\n",
    "    n_clusters = 2\n",
    "    if faq_logits.shape[0] > n_clusters:\n",
    "\n",
    "        # кластеризация найденных вопросов\n",
    "        clustering = cluster.KMeans(n_clusters)\n",
    "        raw_questions = np.concatenate([self.faq_embs[questions_indeces]])\n",
    "        db_clusters = clustering.fit_predict(raw_questions)\n",
    "\n",
    "        # вычисление среднего значения точности кластеров\n",
    "        clusters_score = np.zeros((n_clusters))\n",
    "        clusters_size = np.zeros((n_clusters))\n",
    "\n",
    "        for i, logit in enumerate(faq_logits):\n",
    "            index = db_clusters[i]\n",
    "            clusters_score[index] += logit[1]\n",
    "            clusters_size[index] += 1\n",
    "\n",
    "        clusters_mean_score = clusters_score / clusters_size\n",
    "\n",
    "        # вывод кластеризированных вопросов\n",
    "        max_score_val = clusters_mean_score.max(axis=0)\n",
    "        max_score_index = np.where(clusters_mean_score == max_score_val)[0]\n",
    "\n",
    "        true_faq_lofits = faq_logits[np.where(db_clusters == max_score_index)]\n",
    "        true_questions_indeces = true_faq_lofits[:, 0].astype('int64').reshape((1, -1))\n",
    "\n",
    "        if verbose:\n",
    "            print('\\nCleaned questions')\n",
    "            print('---------------------')\n",
    "            true_questions = self.faq[true_questions_indeces][0, :, 0]\n",
    "            for i, faq_question in enumerate(true_questions):\n",
    "                print('index ', faq_logits[i, 0], ' score ', faq_logits[i, 1], faq_question)\n",
    "\n",
    "        if plot:\n",
    "            # вывод кластеризованных вопросов на плоскость\n",
    "            umap_news = umap.UMAP()\n",
    "            question_emb = self.sent_vectorizer(question).reshape(1, -1)\n",
    "            data = np.concatenate([self.faq_embs[questions_indeces][0], question_emb], axis=0)\n",
    "            umaped_vct = umap_news.fit_transform(data)\n",
    "            questions = self.faq[questions_indeces][:, 0]\n",
    "\n",
    "            myclr = ListedColormap(\n",
    "                choice(list(sns.xkcd_rgb.values()), max(db_clusters) + 1))  # Генерируем контрастную карту цветов.\n",
    "            print('количество кластеров ', max(db_clusters) + 1)\n",
    "            N = 15\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(N, N))\n",
    "\n",
    "            ax.scatter(umaped_vct[:-1, 0], umaped_vct[:-1, 1], s=300, c=db_clusters, cmap=myclr)\n",
    "            ax.scatter(umaped_vct[-1, 0], umaped_vct[-1, 1], s=600, c=1, cmap='rocket')\n",
    "            for i, xy in enumerate(umaped_vct[:-1]):\n",
    "                ax.text(xy[0], xy[1], '   ' + str(faq_logits[i][1]) + ' ' + questions[i], fontsize=20, color='black')\n",
    "\n",
    "            ax.text(umaped_vct[-1, 0], umaped_vct[-1, 1], '   Question: ' + question, fontsize=20, color='black')\n",
    "            plt.show()\n",
    "\n",
    "        return true_questions_indeces.astype('int32')[0]\n",
    "    else:\n",
    "        return questions_indeces.reshape((1, -1)).astype('int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def questions_diffs(self, questions_indeces, min_score, max_score, verbose=False):\n",
    "    \"\"\"\n",
    "    :param self:\n",
    "    :param questions_indeces: list shape (n,)\n",
    "    :param min_score: scalar float [0,1]\n",
    "    :param max_score: scalar float [0,1]\n",
    "    :param verbose: bool\n",
    "    :return: list [[str1,index1],[str2,index2]..]\n",
    "    \"\"\"\n",
    "\n",
    "    questions = self.faq[questions_indeces][:, 0]\n",
    "\n",
    "    words_pool_embs = []\n",
    "    questions_words_embs = []\n",
    "    questions_words = []\n",
    "\n",
    "    for question in questions:\n",
    "        words = question.split()\n",
    "        questions_words.append(words)\n",
    "        words_embs = [self.sent_vectorizer(word) for word in words]\n",
    "        questions_words_embs.append(words_embs)\n",
    "\n",
    "        words_pool_embs = words_pool_embs + words_embs\n",
    "\n",
    "    common_words_indx = []\n",
    "\n",
    "    # поиск повторяющихся слов\n",
    "    for i, word1 in enumerate(words_pool_embs):\n",
    "        word_score = 0\n",
    "\n",
    "        for j, word2 in enumerate(words_pool_embs):\n",
    "            if i != j:\n",
    "                score = 1 - spatial.distance.cosine(word1, word2)\n",
    "                if score > word_score:\n",
    "                    word_score = score\n",
    "\n",
    "        if word_score > min_score:\n",
    "            common_words_indx.append(i)\n",
    "\n",
    "    words_pool_embs = np.array(words_pool_embs)\n",
    "    common_words_embs = words_pool_embs[common_words_indx]\n",
    "    questions_diffs_eye = []\n",
    "\n",
    "    # повторный проход по вопросам\n",
    "    for i, question in enumerate(questions_words_embs):\n",
    "        questions_diffs_eye.append([])\n",
    "\n",
    "        for word1 in question:\n",
    "            word_score = 0\n",
    "            for word2 in common_words_embs:\n",
    "                score = 1 - spatial.distance.cosine(word1, word2)\n",
    "                if score > word_score:\n",
    "                    word_score = score\n",
    "\n",
    "            if word_score > max_score:\n",
    "                # если слово повтторяющееся\n",
    "                questions_diffs_eye[i].append(0)\n",
    "            else:\n",
    "                # если слово уникальное\n",
    "                questions_diffs_eye[i].append(1)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\ndiff indeces ', questions_diffs_eye)\n",
    "        print('-----------')\n",
    "    diff_words = []\n",
    "\n",
    "    for i, question_eye in enumerate(questions_diffs_eye):\n",
    "        question_eye = np.array(question_eye)\n",
    "        indeces = np.where(question_eye == 1)[0]\n",
    "        #   print('indeces ',indeces)\n",
    "\n",
    "        start = indeces[0]\n",
    "        end = indeces[-1]\n",
    "\n",
    "        diff_words.append(questions_words[i][:])\n",
    "\n",
    "    diffs = [[\" \".join(words)] for words in diff_words]\n",
    "    for i, diff in enumerate(diffs):\n",
    "        diff.append(questions_indeces[i])\n",
    "\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compare_answer_diffs(self, diffs, answer):\n",
    "    \"\"\"\n",
    "    :param self:\n",
    "    :param diffs: list [[str1,index1],[str2,index2]..]\n",
    "    :param answer: str\n",
    "    :return: tuple shape (2,), (question_index,score)\n",
    "    \"\"\"\n",
    "    answer_emb = self.sent_vectorizer(answer)\n",
    "    diffs_embs = [self.sent_vectorizer(diff[0]) for diff in diffs]\n",
    "\n",
    "    index = 0\n",
    "    score = 0\n",
    "\n",
    "    for i, diff_emb in enumerate(diffs_embs):\n",
    "        diff_score = 1 - spatial.distance.cosine(diff_emb, answer_emb)\n",
    "        if score < diff_score:\n",
    "            index = i\n",
    "            score = diff_score\n",
    "\n",
    "    true_question_index = diffs[index][1]\n",
    "\n",
    "    return true_question_index, score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system_question(self, diffs):\n",
    "    \"\"\"\n",
    "    :param self:\n",
    "    :param diffs: list [[str1,index1],[str2,index2]..]\n",
    "    :return: str\n",
    "    \"\"\"\n",
    "    morph = self.MorphAnalyzer\n",
    "    system_question = 'Вас интересует '\n",
    "    n = len(diffs)\n",
    "\n",
    "    connectors = []\n",
    "\n",
    "    if n == 2:\n",
    "        connectors = ['или ', '?']\n",
    "    elif n == 3:\n",
    "        connectors = [', ', ' или ', '?']\n",
    "\n",
    "    for i, diff in enumerate(diffs):\n",
    "        diff_words = diff[0].split()\n",
    "        # print('diff ', diff)\n",
    "        q = ''\n",
    "        for word in diff_words:\n",
    "            p = morph.parse(word)[0]\n",
    "            if p.tag.POS == 'NOUN':\n",
    "                q += word + ' '\n",
    "                #q += p.normal_form + ' '\n",
    "            else:\n",
    "                q += word + ' '\n",
    "\n",
    "        system_question += q + connectors[i]\n",
    "\n",
    "    return system_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Как оформить льготу\n",
      "---------------------\n",
      "index  12.0  score  0.7915015816688538 как закрыть льготу\n",
      "index  9.0  score  0.7832639813423157 как оформить льготу в москве\n",
      "index  13.0  score  0.7823385000228882 как оформить льготу в московской области\n",
      "index  11.0  score  0.7518547773361206 какие документы необходимы для оформления или продления или переоформления льготы\n",
      "\n",
      "Cleaned questions\n",
      "---------------------\n",
      "index  12.0  score  0.7915015816688538 как закрыть льготу\n",
      "index  9.0  score  0.7832639813423157 как оформить льготу в москве\n",
      "index  13.0  score  0.7823385000228882 как оформить льготу в московской области\n",
      "\n",
      "diff indeces  [[0, 1, 0], [0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 1]]\n",
      "-----------\n",
      "Вас интересует как закрыть льготу , как оформить льготу в москве  или как оформить льготу в московской области ?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-53-ab5459c0fa88>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     31\u001B[0m     \u001B[1;31m# сравниеаем ответ пользователя и отличающиеся части вопросов\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[1;32mwhile\u001B[0m \u001B[0mflag\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 33\u001B[1;33m         \u001B[0mtrue_question_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscore\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompare_answer_diffs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdiffs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0madditional_answer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     34\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mscore\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0.6\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m             \u001B[0mflag\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-27-3b2c28b326b9>\u001B[0m in \u001B[0;36mcompare_answer_diffs\u001B[1;34m(self, diffs, answer)\u001B[0m\n\u001B[0;32m      7\u001B[0m     \"\"\"\n\u001B[0;32m      8\u001B[0m     \u001B[0manswer_emb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msent_vectorizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[0mdiffs_embs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msent_vectorizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdiff\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mdiff\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdiffs\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-27-3b2c28b326b9>\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      7\u001B[0m     \"\"\"\n\u001B[0;32m      8\u001B[0m     \u001B[0manswer_emb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msent_vectorizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[0mdiffs_embs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msent_vectorizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdiff\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mdiff\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdiffs\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-2-cfd3788c5582>\u001B[0m in \u001B[0;36msent_vectorizer\u001B[1;34m(self, sentence)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     42\u001B[0m         \u001B[1;31m#     with torch.no_grad():\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 43\u001B[1;33m         \u001B[0mmodel_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msbert_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mencoded_input\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     44\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     45\u001B[0m         \u001B[1;31m#Perform pooling. In this case, mean pooling\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    988\u001B[0m             \u001B[0mpast_key_values_length\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpast_key_values_length\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    989\u001B[0m         )\n\u001B[1;32m--> 990\u001B[1;33m         encoder_outputs = self.encoder(\n\u001B[0m\u001B[0;32m    991\u001B[0m             \u001B[0membedding_output\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    992\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mextended_attention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    580\u001B[0m                 )\n\u001B[0;32m    581\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 582\u001B[1;33m                 layer_outputs = layer_module(\n\u001B[0m\u001B[0;32m    583\u001B[0m                     \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    584\u001B[0m                     \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    468\u001B[0m         \u001B[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    469\u001B[0m         \u001B[0mself_attn_past_key_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpast_key_value\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mpast_key_value\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 470\u001B[1;33m         self_attention_outputs = self.attention(\n\u001B[0m\u001B[0;32m    471\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    472\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    399\u001B[0m         \u001B[0moutput_attentions\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    400\u001B[0m     ):\n\u001B[1;32m--> 401\u001B[1;33m         self_outputs = self.self(\n\u001B[0m\u001B[0;32m    402\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    403\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    288\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    289\u001B[0m             \u001B[0mkey_layer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose_for_scores\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 290\u001B[1;33m             \u001B[0mvalue_layer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose_for_scores\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    291\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    292\u001B[0m         \u001B[0mquery_layer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose_for_scores\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmixed_query_layer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 96\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     97\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mlinear\u001B[1;34m(input, weight, bias)\u001B[0m\n\u001B[0;32m   1845\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhas_torch_function_variadic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1846\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mhandle_torch_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1847\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1848\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1849\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#noise = ' пук кряк пиво интерал'\n",
    "#noise2 = ' а то я не умею'\n",
    "#question = faq['Question'][9]\n",
    "#question = 'Как оформить льготу '\n",
    "#question = 'льгота  от расхода'\n",
    "# question='Как будут осуществляться начисления если счетчик сломается'\n",
    "question = 'Как оформить льготу'\n",
    "additional_answer = 'москве'\n",
    "\n",
    "eps = 0.15\n",
    "minimal_score = 0.7\n",
    "\n",
    "# ищем похожие вопросы в датасете\n",
    "# если больше 1 совпадения, кластеризуем и выбираем кластер с наибольшей точностью\n",
    "dirty_indeces = search_faq(engine, question, eps, minimal_score, True)\n",
    "\n",
    "cleaned_indeces = clean_faq(engine, dirty_indeces, True)\n",
    "\n",
    "# если после кластеризации больше 1 совпадения\n",
    "if len(cleaned_indeces) > 1:\n",
    "\n",
    "    # ищем отличающиеся в вопросах слова\n",
    "    diffs = questions_diffs(engine, cleaned_indeces, min_score=0.8, max_score=0.8, verbose=True)\n",
    "    # print(diffs)\n",
    "    # формируем уточняющий вопрос \n",
    "    system_question = create_system_question(engine, diffs)\n",
    "    #print('----------------')\n",
    "    print(system_question)\n",
    "\n",
    "    flag = True\n",
    "    # сравниеаем ответ пользователя и отличающиеся части вопросов\n",
    "    while flag:\n",
    "        true_question_index, score = compare_answer_diffs(engine, diffs, additional_answer)\n",
    "        if score > 0.6:\n",
    "            flag = False\n",
    "            question, answer = engine.faq[true_question_index]\n",
    "            print(true_question_index, score, question)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}