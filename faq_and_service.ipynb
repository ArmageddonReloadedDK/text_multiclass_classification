{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\torch\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from matplotlib.colors import ListedColormap\n",
    "from numpy.random import choice\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from gensim.models import FastText,KeyedVectors,fasttext\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "'''import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape,BatchNormalization,MaxPooling2D,Lambda\n",
    "from tensorflow.keras.layers import Dense,Activation,Reshape,Conv2D,LeakyReLU,concatenate,Flatten\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cluster\n",
    "\n",
    "import seaborn as sns\n",
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Как изменить ФИО собственника?</td>\n",
       "      <td>Для переоформления лицевого счета на нового вл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как исправить ошибку (или опечатку) в ФИОсобст...</td>\n",
       "      <td>Подать заявку на изменение данных можно в личн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как изменить телефон?</td>\n",
       "      <td>Изменить номер мобильного телефона можно самос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Как изменить количество проживающих?</td>\n",
       "      <td>Изменить данные о количестве проживающих можно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Как изменить количество комнат?</td>\n",
       "      <td>Изменить данные о количестве комнат можно толь...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Как изменить площадь квартиры?</td>\n",
       "      <td>Изменить данные о площади квартиры можно тольк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Как изменить адрес для рассылки счетов?</td>\n",
       "      <td>Изменить адрес для рассылки ежемесячных счетов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Как изменить тариф в сельской местности?</td>\n",
       "      <td>В соответствии с Распоряжением Комитета по цен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Порядок проверки приборов учёта и оформления а...</td>\n",
       "      <td>Памятка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Как оформить льготу в Москве?</td>\n",
       "      <td>Для того чтобы использовать льготу при оплате ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                     Как изменить ФИО собственника?   \n",
       "1  Как исправить ошибку (или опечатку) в ФИОсобст...   \n",
       "2                              Как изменить телефон?   \n",
       "3               Как изменить количество проживающих?   \n",
       "4                    Как изменить количество комнат?   \n",
       "5                     Как изменить площадь квартиры?   \n",
       "6            Как изменить адрес для рассылки счетов?   \n",
       "7           Как изменить тариф в сельской местности?   \n",
       "8  Порядок проверки приборов учёта и оформления а...   \n",
       "9                      Как оформить льготу в Москве?   \n",
       "\n",
       "                                              Answer  \n",
       "0  Для переоформления лицевого счета на нового вл...  \n",
       "1  Подать заявку на изменение данных можно в личн...  \n",
       "2  Изменить номер мобильного телефона можно самос...  \n",
       "3  Изменить данные о количестве проживающих можно...  \n",
       "4  Изменить данные о количестве комнат можно толь...  \n",
       "5  Изменить данные о площади квартиры можно тольк...  \n",
       "6  Изменить адрес для рассылки ежемесячных счетов...  \n",
       "7  В соответствии с Распоряжением Комитета по цен...  \n",
       "8                                            Памятка  \n",
       "9  Для того чтобы использовать льготу при оплате ...  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faq=pd.read_csv('faq.csv')\n",
    "\n",
    "faq.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine():\n",
    "    def __init__(self,faq,sbert_name=False,fasttext_path=False):\n",
    "        self.faq=faq\n",
    "        if sbert_name:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            self.sbert_model = AutoModel.from_pretrained(sbert_name)\n",
    "            self.sbert_model.to(self.device)\n",
    "            self.sbert_tokenizer = AutoTokenizer.from_pretrained(sbert_name)\n",
    "            self.sbert_faq_embs=np.array([self.vectorize_sentence_sbert(sent) for sent in self.faq[:,0]])\n",
    "            \n",
    "        if fasttext_path:\n",
    "            self.ft_model= fasttext.FastTextKeyedVectors.load(fasttext_path)\n",
    "            self.ft_faq_embs=np.array([self.vectorize_sentence_ft(sent) for sent in self.faq[:,0]])\n",
    "        \n",
    "    def vectorize_sentence_ft(self,sentence):\n",
    "        txt=sentence.split()\n",
    "        val=0\n",
    "        for word in txt:\n",
    "            val+=self.ft_model[word]\n",
    "\n",
    "        return val/len(txt)\n",
    "    \n",
    "\n",
    "    def vectorize_sentence_sbert(self,sentence):\n",
    "    \n",
    "        encoded_input = self.sbert_tokenizer(sentence,\n",
    "                                             padding=True,\n",
    "                                             truncation=True,\n",
    "                                             max_length=24,\n",
    "                                             return_tensors='pt').to(self.device)\n",
    "\n",
    "   #     with torch.no_grad():\n",
    "        model_output = self.sbert_model(**encoded_input)\n",
    "            \n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        sentence_embedding = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embedding = np.squeeze(sentence_embedding)\n",
    "        \n",
    "        return sentence_embedding.cpu().data.numpy()\n",
    "    \n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def mean_pooling(cls,model_output, attention_mask):\n",
    "        #Mean Pooling - Take attention mask into account for correct averaging\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "    \n",
    "    def search_faq(self,question,eps,minimal_score,mode,beta):\n",
    "        if mode=='fasttext':\n",
    "            vectorizer=self.vectorize_sentence_ft\n",
    "            faq_embs=self.ft_faq_embs\n",
    "        elif mode=='sbert':\n",
    "            vectorizer=self.vectorize_sentence_sbert\n",
    "            faq_embs=self.sbert_faq_embs\n",
    "\n",
    "        question_emb=vectorizer(question)\n",
    "        score=np.zeros((self.faq.shape[0],1))\n",
    "\n",
    "       \n",
    "        for i,faq_emb in enumerate(faq_embs):\n",
    "\n",
    "            distance=1-spatial.distance.cosine( faq_emb,question_emb)\n",
    "            score[i,0]=distance\n",
    "                 \n",
    "        \n",
    "        faq_logits=np.concatenate([faq,faq_embs,score],axis=1)\n",
    "        faq_logits=faq_logits[faq_logits[:, 3].argsort()]\n",
    "        faq_logits=faq_logits[::-1]\n",
    "\n",
    "\n",
    "        max_score=faq_logits[0,3]\n",
    "        display_num=0\n",
    "\n",
    "        for scr in faq_logits[:,2]:\n",
    "            if max_score-scr<eps and scr > minimal_score:\n",
    "                display_num+=1\n",
    "            else:\n",
    "                break\n",
    "         \n",
    "\n",
    "\n",
    "        \n",
    "        return faq_logits[:display_num]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sbert_name=\"sberbank-ai/sbert_large_mt_nlu_ru\"\n",
    "# https://rusvectores.org/ru/models/\n",
    "fasttext_path='weights/model.model'\n",
    "engine=SearchEngine(faq.values,sbert_name,fasttext_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  льгота  от расхода\n",
      "---------------------\n",
      "---------------------\n",
      "---------------------\n",
      "Wall time: 24.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "noise=' пук кряк пиво интерал'\n",
    "noise2=' а то я не умею'\n",
    "question=faq['Question'][51] +noise2+noise\n",
    "#question='Как оформить льготу '\n",
    "question='льгота  от расхода'\n",
    "#question='Как будут осуществляться начисления если счетчик сломается'\n",
    "print('Question: ',question)\n",
    "print('---------------------')\n",
    "\n",
    "eps=0.15\n",
    "minimal_score=0.72\n",
    "beta=1.5\n",
    "\n",
    "modes=['fasttext','sbert','both']\n",
    "mode=modes[1]\n",
    "vectorizer=engine.vectorize_sentence_sbert\n",
    "\n",
    "output=search_faq(engine,question,eps,minimal_score,mode=mode,beta=beta)\n",
    "\n",
    "min_val=0.5\n",
    "#cleaned_question=clean_question(SearchEngine.vectorize_sentence_ft,question,output[:,0],min_val)\n",
    "#print(output)\n",
    "print('---------------------')\n",
    "#print('Cleaned question:',cleaned_question)\n",
    "print('---------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def calculate_faq(question_emb,faq_embs,eps,minimal_score,mode):\n",
    "\n",
    "        score=np.zeros((engine.faq.shape[0],1))\n",
    "        for i,faq_emb in enumerate(faq_embs):\n",
    "            \n",
    "            distance=1-spatial.distance.cosine( faq_emb,question_emb)\n",
    "            score[i,0]=round(distance,4)\n",
    "                 \n",
    "        index=np.arange(len(engine.faq)).reshape((-1,1))\n",
    "        \n",
    "        questions=engine.faq[:,0].reshape((-1,1))\n",
    "        \n",
    "        faq_logits=np.concatenate([index,score],axis=1)\n",
    "        faq_logits=faq_logits[faq_logits[:, 1].argsort()]\n",
    "        faq_logits=faq_logits[::-1]\n",
    "\n",
    "\n",
    "        max_score=faq_logits[0,1]\n",
    "        display_num=0\n",
    "\n",
    "        for scr in faq_logits[:,1]:\n",
    "            if max_score-scr<eps and scr > minimal_score:\n",
    "                display_num+=1\n",
    "            else:\n",
    "                break\n",
    "         \n",
    "        faq_logits=faq_logits[:display_num]\n",
    "        \n",
    "        \n",
    "        return faq_logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faq(engine,question,eps,minimal_score,mode,verbose=False,plot=False):\n",
    "    \n",
    "    if mode=='fasttext':\n",
    "        vectorizer=engine.vectorize_sentence_ft\n",
    "        faq_embs=engine.ft_faq_embs\n",
    "    elif mode=='sbert':\n",
    "        vectorizer=engine.vectorize_sentence_sbert\n",
    "        faq_embs=engine.sbert_faq_embs\n",
    "            \n",
    "    question_emb=vectorizer(question)\n",
    "    faq_logits=calculate_faq(question_emb,faq_embs,eps,minimal_score,mode)\n",
    "    questions_indeces=faq_logits[:,0].astype('int64').reshape((1,-1))\n",
    "    questions=engine.faq[questions_indeces][0,:,0]\n",
    "    \n",
    "    if verbose:\n",
    "        print('Question: ',question)\n",
    "        print('---------------------')\n",
    "        for i,faq_question in enumerate(questions):\n",
    "            print('index ',faq_logits[i,0],' score ', faq_logits[i,1],faq_question)\n",
    "    \n",
    "    n_clusters=2\n",
    "    if faq_logits.shape[0]>n_clusters:\n",
    "\n",
    "        clustering=cluster.KMeans(n_clusters)\n",
    "        #clustering = cluster.OPTICS(min_samples=3, xi=.05, min_cluster_size=.05)\n",
    "\n",
    "        db_clusters = clustering.fit_predict(faq_embs[questions_indeces][0])\n",
    "\n",
    "            \n",
    "        clusters_score=np.zeros((n_clusters))\n",
    "        clusters_size=np.zeros((n_clusters))\n",
    "        \n",
    "        for i,logit in enumerate(faq_logits):\n",
    "            index=db_clusters[i]\n",
    "            clusters_score[index]+=logit[1]\n",
    "            clusters_size[index]+=1\n",
    "        \n",
    "        clusters_mean_score=clusters_score/clusters_size\n",
    "        \n",
    "        max_score_index=0\n",
    "        max_score_val=0\n",
    "        \n",
    "        for i,cluster_val in enumerate(clusters_mean_score):\n",
    "            if cluster_val> max_score_val:\n",
    "                max_score_val=cluster_val\n",
    "                max_score_index=i\n",
    "        \n",
    "        true_faq_lofits=faq_logits[np.where(db_clusters==max_score_index)]\n",
    "        \n",
    "        true_questions_indeces=true_faq_lofits[:,0].astype('int64').reshape((1,-1))\n",
    "        true_questions=engine.faq[true_questions_indeces][0,:,0]\n",
    "            \n",
    "        if verbose:\n",
    "            print('\\nCleaned questions')\n",
    "            print('---------------------')\n",
    "            for i,faq_question in enumerate(true_questions):\n",
    "                print('index ',faq_logits[i,0],' score ', faq_logits[i,1],faq_question)\n",
    "                \n",
    "        \n",
    "        if plot:\n",
    "\n",
    "            umap_news=umap.UMAP()\n",
    "            question_emb=vectorizer(question).reshape(1,-1)\n",
    "            data=np.concatenate([faq_embs[questions_indeces][0],question_emb],axis=0)\n",
    "            umaped_vct=umap_news.fit_transform(data)\n",
    "            questions=engine.faq[questions_indeces][0,:,0]\n",
    "\n",
    "            myclr=ListedColormap(choice(list(sns.xkcd_rgb.values()), max(db_clusters)+1)) # Генерируем контрастную карту цветов.\n",
    "            print('количество кластеров ',max(db_clusters)+1)\n",
    "            N=15\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(N,N))\n",
    "\n",
    "            ax.scatter(umaped_vct[:-1, 0], umaped_vct[:-1, 1], s=300, c=db_clusters, cmap=myclr)\n",
    "            ax.scatter(umaped_vct[-1, 0], umaped_vct[-1, 1], s=600, c=1, cmap='rocket')\n",
    "            for i,xy in enumerate(umaped_vct[:-1]):\n",
    "                ax.text(xy[0], xy[1],'   '+str(faq_logits[i][1])+' ' +questions[i], fontsize=15,  color='black')\n",
    "\n",
    "            ax.text(umaped_vct[-1,0], umaped_vct[-1,1],'   Question: '+ question, fontsize=15,  color='black')\n",
    "            plt.show()\n",
    "        \n",
    "        return true_questions\n",
    "    else:\n",
    "        return questions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Как оформить льготу \n",
      "---------------------\n",
      "index  9.0  score  0.8307 Как оформить льготу в Москве?\n",
      "index  13.0  score  0.8111 Как оформить льготу в Московской области?\n",
      "index  11.0  score  0.7411 Какие документы необходимы для оформления/продления/переоформления льготы?\n",
      "\n",
      "Cleaned questions\n",
      "---------------------\n",
      "index  9.0  score  0.8307 Как оформить льготу в Москве?\n",
      "index  13.0  score  0.8111 Как оформить льготу в Московской области?\n",
      "\n",
      "Questions difference\n",
      "--------------\n",
      "['Москве?', 'Московской области?']\n",
      "Wall time: 261 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "noise=' пук кряк пиво интерал'\n",
    "noise2=' а то я не умею'\n",
    "question=faq['Question'][9] \n",
    "question='Как оформить льготу '\n",
    "#question='льгота  от расхода'\n",
    "#question='Как будут осуществляться начисления если счетчик сломается'\n",
    "\n",
    "\n",
    "eps=0.15\n",
    "minimal_score=0.7\n",
    "beta=1.5\n",
    "\n",
    "modes=['fasttext','sbert']\n",
    "mode=modes[1]\n",
    "\n",
    "output=find_faq(engine,question,eps,minimal_score,mode=mode,verbose=True,plot=False)\n",
    "diff=questions_diff(engine.vectorize_sentence_sbert,questions=output,min_score=0.8,max_score=0.8,verbose=0)\n",
    "print('\\nQuestions difference')\n",
    "print('--------------')\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def questions_diff(vectorizer,questions,min_score,max_score,verbose):\n",
    "    \n",
    "    words_pool_embs=[]\n",
    "    questions_words_embs=[]\n",
    "    questions_words=[]\n",
    "    questions_words_embs_pool=[]\n",
    "    \n",
    "    \n",
    "    for question in questions:\n",
    "        words=question.split()\n",
    "        questions_words.append(words)\n",
    "        words_embs=[vectorizer(word) for word in words]\n",
    "        questions_words_embs.append(words_embs)\n",
    "        \n",
    "        words_pool_embs=words_pool_embs+words_embs\n",
    "    \n",
    "    common_words_indx=[]\n",
    "    \n",
    "    # поиск повторяющихся слов\n",
    "    for i,word1 in enumerate(words_pool_embs):\n",
    "        word_score=0\n",
    "        \n",
    "        for j,word2 in enumerate(words_pool_embs):\n",
    "            if i!=j:\n",
    "                score=1-spatial.distance.cosine(word1, word2)\n",
    "                if score > word_score:\n",
    "                    word_score=score\n",
    "\n",
    "        if word_score>min_score:\n",
    "            common_words_indx.append(i)\n",
    "            \n",
    "    words_pool_embs=np.array(words_pool_embs)\n",
    "  #  print('common indeces ',common_words_indx)\n",
    "    common_words_embs=words_pool_embs[common_words_indx]\n",
    "  #  print(len(common_words_embs))\n",
    "  #  print(len( words_pool_embs))\n",
    "    questions_diffs_eye=[]\n",
    "    \n",
    "    \n",
    "    for i,question in enumerate(questions_words_embs):\n",
    "        questions_diffs_eye.append([])\n",
    "        \n",
    "        for word1 in question:\n",
    "            word_score=0\n",
    "            for word2 in common_words_embs:\n",
    "                score=1-spatial.distance.cosine(word1, word2)\n",
    "                if score > word_score:\n",
    "                    word_score=score\n",
    "                    \n",
    "            if word_score>max_score:\n",
    "                # если слово повтторяющееся\n",
    "                questions_diffs_eye[i].append(0)\n",
    "            else:\n",
    "                # если слово уникальное\n",
    "                questions_diffs_eye[i].append(1)\n",
    "                \n",
    "    questions_diffs_eye=np.array(questions_diffs_eye)\n",
    "    if verbose:\n",
    "        \n",
    "        print('\\ndiff indeces ',questions_diffs_eye)\n",
    "        print('-----------')\n",
    "    diff_words=[]\n",
    "    \n",
    "    for i,question_eye in enumerate(questions_diffs_eye):\n",
    "\n",
    "        question_eye=np.array(question_eye)\n",
    "        indeces=np.where(question_eye==1)[0]\n",
    "       \n",
    "        start=indeces[0]\n",
    "        end=indeces[-1]+1\n",
    "   #     print('indeces ',indeces)\n",
    "        diff_words.append(questions_words[i][start:end])\n",
    "    \n",
    "    \n",
    "    return [\" \".join(words) for words in diff_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=['Сборка простой люстры',\n",
    "'Сборка сложной люстры',\n",
    "'Установка простой люстры',\n",
    "'Установка сложной люстры',\n",
    "'Установка светильника типа Армстронг',\n",
    "'Установка светильника настенного, бра',\n",
    "'Установка точечного светильника',\n",
    "'Подключение светильника Выход',\n",
    "'Подключени трансформатора для галогенных ламп',\n",
    "'Установка антивандального светильника']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=questions[:2]\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2=questions[4:7]\n",
    "q2_words=[]\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "for q in q2:\n",
    "    words=q.split()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0] \n",
    "        q2_words.append(p.normal_form)\n",
    "        \n",
    "q2_words=set(q2_words)\n",
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "word = \"светильником\"\n",
    "p = morph.parse(word)[0]  # Делаем полный разбор, и берем первый вариант разбора (условно \"самый вероятный\", но не факт что правильный)\n",
    "print(p.normal_form)  # стать"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
