{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from matplotlib.colors import ListedColormap\n",
    "from numpy.random import choice\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "import re\n",
    "\n",
    "from gensim.models import FastText,KeyedVectors,fasttext\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel, AutoModel\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cluster\n",
    "\n",
    "import seaborn as sns\n",
    "import umap\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='models/sbert_large_mt_nlu_ru/4'\n",
    "model = TFAutoModel.from_pretrained(path)\n",
    "#model = AutoModel.from_pretrained(path)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('faq.csv', delimiter=',',encoding='utf-8',dtype=str,usecols=(0,1))[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deprecated"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ft_model= fasttext.FastTextKeyedVectors.load('path')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def vectorize_sentence_ft(self,sentence):\n",
    "    txt=sentence.split()\n",
    "    val=0\n",
    "    for word in txt:\n",
    "        val+=self.ft_model[word]\n",
    "\n",
    "    return val/len(txt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine():\n",
    "    def __init__(self,faq,sbert_path=False):\n",
    "        self.faq=faq\n",
    "        if sbert_path:\n",
    "            start = time.time()\n",
    "            \n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            self.sbert_model = AutoModel.from_pretrained(sbert_path)\n",
    "            self.sbert_model.to(self.device)\n",
    "            self.sbert_tokenizer = AutoTokenizer.from_pretrained(sbert_path)\n",
    "            self.faq_embs=np.array([self.sent_vectorizer(sent) for sent in self.faq[:,0]])\n",
    "            \n",
    "            end = time.time()\n",
    "            self.MorphAnalyzer= pymorphy2.MorphAnalyzer()\n",
    "            print('Sbert model and faq successfully loaded\\nPassed time:',round(end - start,2),'s')\n",
    "\n",
    "\n",
    "    def sent_vectorizer(self,sentence):\n",
    "    \n",
    "        encoded_input = self.sbert_tokenizer(sentence,\n",
    "                                             padding=True,\n",
    "                                             truncation=True,\n",
    "                                             max_length=24,\n",
    "                                             return_tensors='pt').to(self.device)\n",
    "\n",
    "   #     with torch.no_grad():\n",
    "        model_output = self.sbert_model(**encoded_input)\n",
    "            \n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        sentence_embedding = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embedding = np.squeeze(sentence_embedding)\n",
    "        \n",
    "        return sentence_embedding.cpu().data.numpy()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def mean_pooling(cls,model_output, attention_mask):\n",
    "        #Mean Pooling - Take attention mask into account for correct averaging\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbert model and faq successfully loaded\n",
      "Passed time: 11.49 s\n"
     ]
    }
   ],
   "source": [
    "sbert_path = \"models/sbert_large_mt_nlu_ru\"\n",
    "faq = genfromtxt('faq.csv', delimiter=',',encoding='utf-8',dtype=str,usecols=(0,1))[1:]\n",
    "\n",
    "engine = SearchEngine(faq, sbert_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def search_faq(self,question,eps,minimal_score,verbose=False):\n",
    "    '''\n",
    "    :param question: str\n",
    "    :param eps: scalar float [0,1]\n",
    "    :param minimal_score: scalar float [0,1]\n",
    "    :return: ndarray shape (n,2); [[index1, score1], [index2, score2]..]\n",
    "    '''\n",
    "\n",
    "    question_emb=self.sent_vectorizer(question)\n",
    "    score=np.zeros((self.faq.shape[0],1))\n",
    "\n",
    "    # обход всего датасета эмбеддингов вопросов\n",
    "    for i,faq_emb in enumerate(self.faq_embs):\n",
    "        score[i,0]=1-spatial.distance.cosine( faq_emb,question_emb)\n",
    "\n",
    "    # индексы эмбеддингов для сортировки\n",
    "    indeces=np.arange(0,self.faq.shape[0]).reshape((-1,1))\n",
    "\n",
    "    # сортировка\n",
    "    faq_logits=np.concatenate([indeces,score],axis=1)\n",
    "    faq_logits=faq_logits[faq_logits[:, 1].argsort()[::-1]]\n",
    "\n",
    "    # выислиение количества индексов для вывода\n",
    "    max_score=faq_logits[0,1]\n",
    "    display_num=0\n",
    "\n",
    "    for scr in faq_logits[:,1]:\n",
    "        if max_score-scr<eps and scr > minimal_score:\n",
    "            display_num+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print('Question: ',question)\n",
    "        print('---------------------')\n",
    "        questions_indeces=faq_logits[:,0].astype('int64')\n",
    "        questions=self.faq[questions_indeces][:display_num,0]\n",
    "        for i,faq_question in enumerate(questions):\n",
    "            print('index ',faq_logits[i,0],' score ', faq_logits[i,1],faq_question)\n",
    "\n",
    "\n",
    "\n",
    "    return faq_logits[:display_num]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "def clean_faq(self,faq_logits,verbose=False,plot=False):\n",
    "    \"\"\"\n",
    "    :param self:\n",
    "    :param faq_logits: ndarray shape (n,2); [[index1, score1], [index2, score2]..]\n",
    "    :param verbose: bool\n",
    "    :param plot: bool\n",
    "    :return: ndarray shape (n,), [index1,index2,index3..]\n",
    "    \"\"\"\n",
    "\n",
    "    questions_indeces=faq_logits[:,0].astype('int64')\n",
    "\n",
    "    n_clusters=2\n",
    "    if faq_logits.shape[0]>n_clusters:\n",
    "\n",
    "        # кластеризация найденных вопросов\n",
    "        clustering=cluster.KMeans(n_clusters)\n",
    "        raw_questions=np.concatenate([self.faq_embs[questions_indeces]])\n",
    "        db_clusters = clustering.fit_predict(raw_questions)\n",
    "\n",
    "        # вычисление среднего значения точности кластеров\n",
    "        clusters_score=np.zeros((n_clusters))\n",
    "        clusters_size=np.zeros((n_clusters))\n",
    "\n",
    "        for i,logit in enumerate(faq_logits):\n",
    "            index=db_clusters[i]\n",
    "            clusters_score[index]+=logit[1]\n",
    "            clusters_size[index]+=1\n",
    "\n",
    "        clusters_mean_score=clusters_score/clusters_size\n",
    "\n",
    "        # вывод кластеризированных вопросов\n",
    "        max_score_val=clusters_mean_score.max(axis=0)\n",
    "        max_score_index=np.where(clusters_mean_score==max_score_val)[0]\n",
    "\n",
    "        true_faq_lofits=faq_logits[np.where(db_clusters==max_score_index)]\n",
    "        true_questions_indeces=true_faq_lofits[:,0].astype('int64').reshape((1,-1))\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            print('\\nCleaned questions')\n",
    "            print('---------------------')\n",
    "            true_questions=self.faq[true_questions_indeces][0,:,0]\n",
    "            for i,faq_question in enumerate(true_questions):\n",
    "                print('index ',faq_logits[i,0],' score ', faq_logits[i,1],faq_question)\n",
    "\n",
    "\n",
    "        if plot:\n",
    "            # вывод кластеризованных вопросов на плоскость\n",
    "            umap_news=umap.UMAP()\n",
    "            question_emb=self.sent_vectorizer(question).reshape(1,-1)\n",
    "            data=np.concatenate([self.faq_embs[questions_indeces][0],question_emb],axis=0)\n",
    "            umaped_vct=umap_news.fit_transform(data)\n",
    "            questions=self.faq[questions_indeces][:,0]\n",
    "\n",
    "            myclr=ListedColormap(choice(list(sns.xkcd_rgb.values()), max(db_clusters)+1)) # Генерируем контрастную карту цветов.\n",
    "            print('количество кластеров ',max(db_clusters)+1)\n",
    "            N=15\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(N,N))\n",
    "\n",
    "            ax.scatter(umaped_vct[:-1, 0], umaped_vct[:-1, 1], s=300, c=db_clusters, cmap=myclr)\n",
    "            ax.scatter(umaped_vct[-1, 0], umaped_vct[-1, 1], s=600, c=1, cmap='rocket')\n",
    "            for i,xy in enumerate(umaped_vct[:-1]):\n",
    "                ax.text(xy[0], xy[1],'   '+str(faq_logits[i][1])+' ' +questions[i], fontsize=20,  color='black')\n",
    "\n",
    "            ax.text(umaped_vct[-1,0], umaped_vct[-1,1],'   Question: '+ question, fontsize=20,  color='black')\n",
    "            plt.show()\n",
    "\n",
    "        return true_questions_indeces.astype('int32')[0]\n",
    "    else:\n",
    "        return questions_indeces.reshape((1,-1)).astype('int32')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  как оформить льготу\n",
      "---------------------\n",
      "index  9.0  score  0.8306976556777954 Как оформить льготу в Москве?\n",
      "index  13.0  score  0.811086893081665 Как оформить льготу в Московской области?\n",
      "index  11.0  score  0.7411444187164307 Какие документы необходимы для оформления/продления/переоформления льготы?\n",
      "\n",
      "Cleaned questions\n",
      "---------------------\n",
      "index  9.0  score  0.8306976556777954 Как оформить льготу в Москве?\n",
      "index  13.0  score  0.811086893081665 Как оформить льготу в Московской области?\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[ 9, 13]], dtype=int64)"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_faq(engine,search_faq(engine,'как оформить льготу', 0.2,0.7,True),True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "def questions_diffs(self,questions_indeces,min_score,max_score,verbose=False):\n",
    "\n",
    "    questions=self.faq[questions_indeces][:,0]\n",
    "\n",
    "    words_pool_embs=[]\n",
    "    questions_words_embs=[]\n",
    "    questions_words=[]\n",
    "    questions_words_embs_pool=[]\n",
    "\n",
    "\n",
    "    for question in questions:\n",
    "        words=question.split()\n",
    "        questions_words.append(words)\n",
    "        words_embs=[self.sent_vectorizer(word) for word in words]\n",
    "        questions_words_embs.append(words_embs)\n",
    "\n",
    "        words_pool_embs=words_pool_embs+words_embs\n",
    "\n",
    "    common_words_indx=[]\n",
    "\n",
    "    # поиск повторяющихся слов\n",
    "    for i,word1 in enumerate(words_pool_embs):\n",
    "        word_score=0\n",
    "\n",
    "        for j,word2 in enumerate(words_pool_embs):\n",
    "            if i!=j:\n",
    "                score=1-spatial.distance.cosine(word1, word2)\n",
    "                if score > word_score:\n",
    "                    word_score=score\n",
    "\n",
    "        if word_score>min_score:\n",
    "            common_words_indx.append(i)\n",
    "\n",
    "    words_pool_embs=np.array(words_pool_embs)\n",
    "    common_words_embs=words_pool_embs[common_words_indx]\n",
    "    questions_diffs_eye=[]\n",
    "\n",
    "    # повторный проход по вопросам\n",
    "    for i,question in enumerate(questions_words_embs):\n",
    "        questions_diffs_eye.append([])\n",
    "\n",
    "        for word1 in question:\n",
    "            word_score=0\n",
    "            for word2 in common_words_embs:\n",
    "                score=1-spatial.distance.cosine(word1, word2)\n",
    "                if score > word_score:\n",
    "                    word_score=score\n",
    "\n",
    "            if word_score>max_score:\n",
    "                # если слово повтторяющееся\n",
    "                questions_diffs_eye[i].append(0)\n",
    "            else:\n",
    "                # если слово уникальное\n",
    "                questions_diffs_eye[i].append(1)\n",
    "\n",
    "    questions_diffs_eye=np.array(questions_diffs_eye)\n",
    "    if verbose:\n",
    "\n",
    "        print('\\ndiff indeces ',questions_diffs_eye)\n",
    "        print('-----------')\n",
    "    diff_words=[]\n",
    "\n",
    "    for i,question_eye in enumerate(questions_diffs_eye):\n",
    "        question_eye=np.array(question_eye)\n",
    "        indeces=np.where(question_eye==1)[0]\n",
    "     #   print('indeces ',indeces)\n",
    "\n",
    "        start=indeces[0]\n",
    "        end=indeces[-1]+1\n",
    "\n",
    "        diff_words.append(questions_words[i][start:end])\n",
    "\n",
    "    diffs= [[\" \".join(words)] for words in diff_words]\n",
    "    for i,diff in enumerate(diffs):\n",
    "        diff.append(questions_indeces[i])\n",
    "\n",
    "    return diffs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "def compare_answer_diffs(self,diffs_logits,answer):\n",
    "\n",
    "    answer_emb=self.sent_vectorizer(answer)\n",
    "    diffs_embs=[self.sent_vectorizer(logit[0]) for logit in diffs_logits]\n",
    "\n",
    "    index=0\n",
    "    score=0\n",
    "\n",
    "    for i,diff_emb in enumerate(diffs_embs):\n",
    "        diff_score=1-spatial.distance.cosine(diff_emb,answer_emb)\n",
    "        if score<diff_score:\n",
    "            index=i\n",
    "            score=diff_score\n",
    "\n",
    "    diff_index=diffs_logits[index][1]\n",
    "    question,answer=self.faq[diff_index]\n",
    "\n",
    "    return question,diff_index,answer,score\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system_question(self,diffs):\n",
    "\n",
    "\n",
    "        morph = self.MorphAnalyzer\n",
    "        system_question='Вас интересует '\n",
    "        n=len(diffs)\n",
    "\n",
    "        connectors=[]\n",
    "\n",
    "        if n==2:\n",
    "            connectors=['или ','?']\n",
    "        elif n==3:\n",
    "            connectors = [', ', ' или ','?']\n",
    "\n",
    "        for i,diff in enumerate(diffs):\n",
    "            diff_words=diff[0].split()\n",
    "            q=''\n",
    "            for word in diff_words:\n",
    "                p = morph.parse(word)[0]\n",
    "                if p.tag.POS=='NOUN':\n",
    "                    q+=p.normal_form+' '\n",
    "                else:\n",
    "                    q += word+' '\n",
    "\n",
    "            system_question+=q+connectors[i]\n",
    "            \n",
    "        return system_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Как оформить льготу\n",
      "---------------------\n",
      "index  9.0  score  0.8306976556777954 Как оформить льготу в Москве?\n",
      "index  13.0  score  0.811086893081665 Как оформить льготу в Московской области?\n",
      "index  11.0  score  0.7411444187164307 Какие документы необходимы для оформления/продления/переоформления льготы?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-159-1490af9c276a>:56: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  questions_diffs_eye=np.array(questions_diffs_eye)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "diff indeces  [list([0, 0, 0, 0, 1]) list([0, 0, 0, 0, 1, 1])]\n",
      "-----------\n",
      "Вас интересует Москве? или Московской области? ?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#noise = ' пук кряк пиво интерал'\n",
    "#noise2 = ' а то я не умею'\n",
    "#question = faq['Question'][9]\n",
    "#question = 'Как оформить льготу '\n",
    "# question='льгота  от расхода'\n",
    "# question='Как будут осуществляться начисления если счетчик сломается'\n",
    "question='Как оформить льготу'\n",
    "\n",
    "eps = 0.15\n",
    "minimal_score = 0.7\n",
    "\n",
    "# ищем похожие вопросы в датасете\n",
    "# если больше 1 совпадения, кластеризуем и выбираем кластер с наибольшей точностью\n",
    "faq_logits = search_faq(engine, question, eps, minimal_score, verbose=True)\n",
    "\n",
    "cleaned_output=clean_faq(engine,faq_logits)\n",
    "\n",
    "# если после кластеризации больше 1 совпадения\n",
    "if len(cleaned_output)>1:\n",
    "\n",
    "    # ищем отличающиеся в вопросах слова\n",
    "    diffs = questions_diffs(engine,cleaned_output, min_score=0.8, max_score=0.8,verbose=True)\n",
    "   \n",
    "    # формируем уточняющий вопрос \n",
    "    system_question=create_system_question(engine,diffs)\n",
    "    print(system_question)\n",
    "\n",
    "    flag=True\n",
    "    # сравниеаем ответ пользователя и отличающиеся части вопросов\n",
    "    while flag:\n",
    "        answer=input()\n",
    "        question,question_index,asnwer,score = compare_answer_diffs(engine, diffs, answer)\n",
    "        if score>0.6:\n",
    "            flag=False\n",
    "            print(question,question_index,score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbert model and faq successfully loaded\n",
      "Passed time: 10.08 s\n"
     ]
    }
   ],
   "source": [
    "sbert_name = \"models/sbert_large_mt_nlu_ru\"\n",
    "# https://rusvectores.org/ru/models/\n",
    "#fasttext_path = 'weights/model.model'\n",
    "\n",
    "faq = pd.read_csv('faq.csv')\n",
    "engine = SearchEngine(faq.values, sbert_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Москве?', 9], ['Московской области?', 13]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Как оформить льготу в Москве?',\n",
       "        'Для того чтобы использовать льготу при оплате за электроэнергию, ее необходимо оформить/продлить/переоформить вАО «Мосэнергосбыт» одним из удобных способов:В\\xa0Едином личном кабинете клиента\\xa0вовкладке «Льготы» (с прикреплением необходимых документов);Воспользоваться терминалом видеосвязи (Автоматизированная система «Видеоконсультант») с операторомКонтактного центра, установленным в МФЦ. Часы работы: Пн-Пт с 08:30 до 20:00.В\\xa0любом\\xa0отделении\\xa0АО\\xa0«Мосэнергосбыт».В качестве заявителей могут выступать физические лица, проживающие в городе Москве и обладающие правом на льготы по оплате за электроэнергию в соответствии с нормативными правовыми актами Российской Федерации или города Москвы, и обратившиеся с заявлением. Интересы заявителей, могут представлять законные представители заявителей или иные лица, уполномоченные заявителем в установленном порядке.В соответствии с законодательством РФ льготы по оплате электроэнергии предоставляются гражданам не более чем на одну квартиру (жилое помещение).'],\n",
       "       ['Как оформить льготу в Московской области?',\n",
       "        'В соответствии с\\xa0законом Московской области от 23 марта 2006 г. №\\xa036/2006-ОЗ «О социальной поддержке отдельных категорий граждан в Московской области», принятым постановлением Московской областной Думы от 15 марта 2006 г. № 5/171-П, регистрация льгот в Московской области не производится, оплата за потребленную электроэнергию производится в полном объеме согласно действующим тарифам. По вопросу возмещения льгот необходимо обращаться в отделение социальной защиты Вашего муниципального района.']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.faq[output[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "noise=' пук кряк пиво интерал'\n",
    "noise2=' а то я не умею'\n",
    "question=faq['Question'][9] \n",
    "question='Как оформить льготу '\n",
    "#question='льгота  от расхода'\n",
    "#question='Как будут осуществляться начисления если счетчик сломается'\n",
    "\n",
    "\n",
    "eps=0.15\n",
    "minimal_score=0.7\n",
    "beta=1.5\n",
    "\n",
    "modes=['fasttext','sbert']\n",
    "mode=modes[1]\n",
    "\n",
    "output=find_faq(engine,question,eps,minimal_score,mode=mode,verbose=True,plot=False)\n",
    "diffs=questions_diff(engine.sent_vectorizer,questions_indeces=output,min_score=0.8,max_score=0.8,verbose=0)\n",
    "print('\\nQuestions difference')\n",
    "print('--------------')\n",
    "print(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "answer='московской области'\n",
    "question=diff_search(engine,diffs,answer,mode)\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1=engine.sent_vectorizer('москва')\n",
    "vect2=engine.sent_vectorizer('московская область')\n",
    "vect3=engine.sent_vectorizer('город')\n",
    "engine.cos_dist(vect1,vect3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph.parse('области')[0].normal_form\n",
    "# ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=['Сборка простой люстры',\n",
    "'Сборка сложной люстры',\n",
    "'Установка простой люстры',\n",
    "'Установка сложной люстры',\n",
    "'Установка светильника типа Армстронг',\n",
    "'Установка светильника настенного, бра',\n",
    "'Установка точечного светильника',\n",
    "'Подключение светильника Выход',\n",
    "'Подключени трансформатора для галогенных ламп',\n",
    "'Установка антивандального светильника']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=questions[:2]\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2=questions[4:7]\n",
    "q2_words=[]\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "for q in q2:\n",
    "    words=q.split()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0] \n",
    "        q2_words.append(p.normal_form)\n",
    "        \n",
    "q2_words=set(q2_words)\n",
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "word = \"светильником\"\n",
    "p = morph.parse(word)[0]  # Делаем полный разбор, и берем первый вариант разбора (условно \"самый вероятный\", но не факт что правильный)\n",
    "print(p.normal_form)  # стать"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}