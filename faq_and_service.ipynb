{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\torch\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from matplotlib.colors import ListedColormap\n",
    "from numpy.random import choice\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from gensim.models import FastText,KeyedVectors,fasttext\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "'''import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape,BatchNormalization,MaxPooling2D,Lambda\n",
    "from tensorflow.keras.layers import Dense,Activation,Reshape,Conv2D,LeakyReLU,concatenate,Flatten\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cluster\n",
    "\n",
    "import seaborn as sns\n",
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Как изменить ФИО собственника?</td>\n",
       "      <td>Для переоформления лицевого счета на нового вл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как исправить ошибку (или опечатку) в ФИОсобст...</td>\n",
       "      <td>Подать заявку на изменение данных можно в личн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как изменить телефон?</td>\n",
       "      <td>Изменить номер мобильного телефона можно самос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Как изменить количество проживающих?</td>\n",
       "      <td>Изменить данные о количестве проживающих можно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Как изменить количество комнат?</td>\n",
       "      <td>Изменить данные о количестве комнат можно толь...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0                     Как изменить ФИО собственника?   \n",
       "1  Как исправить ошибку (или опечатку) в ФИОсобст...   \n",
       "2                              Как изменить телефон?   \n",
       "3               Как изменить количество проживающих?   \n",
       "4                    Как изменить количество комнат?   \n",
       "\n",
       "                                              Answer  \n",
       "0  Для переоформления лицевого счета на нового вл...  \n",
       "1  Подать заявку на изменение данных можно в личн...  \n",
       "2  Изменить номер мобильного телефона можно самос...  \n",
       "3  Изменить данные о количестве проживающих можно...  \n",
       "4  Изменить данные о количестве комнат можно толь...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faq=pd.read_csv('faq.csv')\n",
    "faq.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine():\n",
    "    def __init__(self,faq,sbert_name=False,fasttext_path=False):\n",
    "        self.faq=faq\n",
    "        if sbert_name:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            self.sbert_model = AutoModel.from_pretrained(sbert_name)\n",
    "            self.sbert_model.to(self.device)\n",
    "            self.sbert_tokenizer = AutoTokenizer.from_pretrained(sbert_name)\n",
    "            self.sbert_faq_embs=np.array([self.vectorize_sentence_sbert(sent) for sent in self.faq[:,0]])\n",
    "            \n",
    "        if fasttext_path:\n",
    "            self.ft_model= fasttext.FastTextKeyedVectors.load(fasttext_path)\n",
    "            self.ft_faq_embs=np.array([self.vectorize_sentence_ft(sent) for sent in self.faq[:,0]])\n",
    "        \n",
    "    def vectorize_sentence_ft(self,sentence):\n",
    "        txt=sentence.split()\n",
    "        val=0\n",
    "        for word in txt:\n",
    "            val+=self.ft_model[word]\n",
    "\n",
    "        return val/len(txt)\n",
    "    \n",
    "\n",
    "    def vectorize_sentence_sbert(self,sentence):\n",
    "    \n",
    "        encoded_input = self.sbert_tokenizer(sentence,\n",
    "                                             padding=True,\n",
    "                                             truncation=True,\n",
    "                                             max_length=24,\n",
    "                                             return_tensors='pt').to(self.device)\n",
    "\n",
    "   #     with torch.no_grad():\n",
    "        model_output = self.sbert_model(**encoded_input)\n",
    "            \n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        sentence_embedding = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embedding = np.squeeze(sentence_embedding)\n",
    "        \n",
    "        return sentence_embedding.cpu().data.numpy()\n",
    "    \n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def mean_pooling(cls,model_output, attention_mask):\n",
    "        #Mean Pooling - Take attention mask into account for correct averaging\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "    \n",
    "    def search_faq(self,question,eps,minimal_score,mode,beta):\n",
    "        if mode=='fasttext':\n",
    "            vectorizer=self.vectorize_sentence_ft\n",
    "            faq_embs=self.ft_faq_embs\n",
    "        elif mode=='sbert':\n",
    "            vectorizer=self.vectorize_sentence_sbert\n",
    "            faq_embs=self.sbert_faq_embs\n",
    "\n",
    "        question_emb=vectorizer(question)\n",
    "        score=np.zeros((self.faq.shape[0],1))\n",
    "\n",
    "       \n",
    "        for i,faq_emb in enumerate(faq_embs):\n",
    "\n",
    "            distance=1-spatial.distance.cosine( faq_emb,question_emb)\n",
    "            score[i,0]=distance\n",
    "                 \n",
    "        \n",
    "        faq_logits=np.concatenate([faq,faq_embs,score],axis=1)\n",
    "        faq_logits=faq_logits[faq_logits[:, 3].argsort()]\n",
    "        faq_logits=faq_logits[::-1]\n",
    "\n",
    "\n",
    "        max_score=faq_logits[0,3]\n",
    "        display_num=0\n",
    "\n",
    "        for scr in faq_logits[:,2]:\n",
    "            if max_score-scr<eps and scr > minimal_score:\n",
    "                display_num+=1\n",
    "            else:\n",
    "                break\n",
    "         \n",
    "\n",
    "\n",
    "        \n",
    "        return faq_logits[:display_num]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sbert_name=\"sberbank-ai/sbert_large_mt_nlu_ru\"\n",
    "# https://rusvectores.org/ru/models/\n",
    "fasttext_path='214/model.model'\n",
    "engine=SearchEngine(faq.values,sbert_name,fasttext_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  льгота  от расхода\n",
      "---------------------\n",
      "(array([[16.    ,  0.9035],\n",
      "       [14.    ,  0.8958],\n",
      "       [15.    ,  0.7986]]), array([[['Льгота 100 % от расхода',\n",
      "         'Граждане, которым предусмотрена скидка в размере 100% от расхода по оплате электроэнергии, освобождаются от оплаты за потребленную электроэнергию. Льгота может распространяться как на одного льготника (от оплаты за электроэнергию освобождается только та часть расхода, которая приходится на льготника), так и на льготника с учетом членов его семьи. С перечнем льготных категорий граждан, которым полагается данная льгота можно ознакомиться в Постановлении\\xa0Правительства Москвы от 07.12.2004г. № 850-ПП «О порядке и условиях обеспечения мер социальной поддержки граждан по оплате жилья и коммунальных услуг».'],\n",
      "        ['Льгота 50% от расхода',\n",
      "         'Льгота, предусматривающая скидку 50% от расхода электроэнергии, распространяется на весь расход электроэнергии в квартире, вне зависимости от количества проживающих совместно с льготником. Данный вид льготы не суммируется с другими льготами.'],\n",
      "        ['Льгота 50% (30%) от норматива',\n",
      "         'В соответствии с\\xa0Постановлением Правительства г. Москвы от 20 декабря 1994 г. № 1161\\xa0для граждан, имеющих право на пользование льготой в пределах норматива потребления, установлены следующие нормативные величины:Одинокие граждане, проживающие в квартире, оборудованной:Газовой плитой -\\xa050 кВт·чЭлектрической плитой -\\xa080\\xa0кВт·чСемейные граждане, проживающие в квартире, оборудованной:Газовой плитой\\xa0- 45\\xa0кВт·чЭлектрической плитой\\xa0- 70\\xa0кВт·чНорматив установлен на месяц.Если объем электроэнергии, потребленный в расчетном периоде, больше льготного норматива, то скидка в 50% предоставляется на объем в пределах норматива потребления, а оставшиеся часть оплачивается в размере 100% от тарифа.Если в первой части календарного месяца абонент не в полном объеме использовал полагающийся ему льготный норматив, то остаток будет предоставлен во второй части данного календарного месяца, т.е. в счете за следующий расчетный период. Если величина льготного норматива в первой части календарного месяца использована в полном объеме, то на оставшуюся часть расхода данного календарного месяца, относящуюся к следующему расчетному периоду, нормативная льгота не начисляется.При наличии на счете 2-х и более нормативных льгот, при расчете норматив суммируется.']]],\n",
      "      dtype=object))\n",
      "---------------------\n",
      "---------------------\n",
      "Wall time: 25.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "noise=' пук кряк пиво интерал'\n",
    "noise2=' а то я не умею'\n",
    "question=faq['Question'][51] +noise2+noise\n",
    "#question='Как оформить льготу '\n",
    "question='льгота  от расхода'\n",
    "#question='Как будут осуществляться начисления если счетчик сломается'\n",
    "print('Question: ',question)\n",
    "print('---------------------')\n",
    "\n",
    "eps=0.15\n",
    "minimal_score=0.72\n",
    "beta=1.5\n",
    "\n",
    "modes=['fasttext','sbert','both']\n",
    "mode=modes[1]\n",
    "vectorizer=engine.vectorize_sentence_sbert\n",
    "\n",
    "output=search_faq(engine,question,eps,minimal_score,mode=mode,beta=beta)\n",
    "\n",
    "min_val=0.5\n",
    "#cleaned_question=clean_question(SearchEngine.vectorize_sentence_ft,question,output[:,0],min_val)\n",
    "print(output)\n",
    "print('---------------------')\n",
    "#print('Cleaned question:',cleaned_question)\n",
    "print('---------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " def calculate_faq(question_emb,faq_embs,eps,minimal_score,mode):\n",
    "\n",
    "        score=np.zeros((engine.faq.shape[0],1))\n",
    "        for i,faq_emb in enumerate(faq_embs):\n",
    "            \n",
    "            distance=1-spatial.distance.cosine( faq_emb,question_emb)\n",
    "            score[i,0]=round(distance,4)\n",
    "                 \n",
    "        index=np.arange(len(engine.faq)).reshape((-1,1))\n",
    "        \n",
    "        questions=engine.faq[:,0].reshape((-1,1))\n",
    "        \n",
    "        faq_logits=np.concatenate([index,score],axis=1)\n",
    "        faq_logits=faq_logits[faq_logits[:, 1].argsort()]\n",
    "        faq_logits=faq_logits[::-1]\n",
    "\n",
    "\n",
    "        max_score=faq_logits[0,1]\n",
    "        display_num=0\n",
    "\n",
    "        for scr in faq_logits[:,1]:\n",
    "            if max_score-scr<eps and scr > minimal_score:\n",
    "                display_num+=1\n",
    "            else:\n",
    "                break\n",
    "         \n",
    "        faq_logits=faq_logits[:display_num]\n",
    "        \n",
    "        \n",
    "        return faq_logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faq(engine,question,eps,minimal_score,mode,verbose=False,plot=False):\n",
    "    \n",
    "    if mode=='fasttext':\n",
    "        vectorizer=engine.vectorize_sentence_ft\n",
    "        faq_embs=engine.ft_faq_embs\n",
    "    elif mode=='sbert':\n",
    "        vectorizer=engine.vectorize_sentence_sbert\n",
    "        faq_embs=engine.sbert_faq_embs\n",
    "            \n",
    "    question_emb=vectorizer(question)\n",
    "    faq_logits=calculate_faq(question_emb,faq_embs,eps,minimal_score,mode)\n",
    "    questions_indeces=faq_logits[:,0].astype('int64').reshape((1,-1))\n",
    "    \n",
    "    if verbose:\n",
    "        print('Question: ',question)\n",
    "        print('---------------------')\n",
    "        questions=engine.faq[questions_indeces][0,:,0]\n",
    "        for i,faq_question in enumerate(questions):\n",
    "            print(faq_logits[i,1],faq_question)\n",
    "    \n",
    "    n_clusters=2\n",
    "    if faq_logits.shape[0]>=n_clusters:\n",
    "\n",
    "        clustering=cluster.KMeans(n_clusters)\n",
    "        #clustering = cluster.OPTICS(min_samples=3, xi=.05, min_cluster_size=.05)\n",
    "\n",
    "        db_clusters = clustering.fit_predict(faq_embs[questions_indeces][0])\n",
    "\n",
    "        if plot:\n",
    "\n",
    "            umap_news=umap.UMAP()\n",
    "            question_emb=vectorizer(question).reshape(1,-1)\n",
    "            data=np.concatenate([faq_embs[questions_indeces][0],question_emb],axis=0)\n",
    "            umaped_vct=umap_news.fit_transform(data)\n",
    "            questions=engine.faq[questions_indeces][0,:,0]\n",
    "\n",
    "            myclr=ListedColormap(choice(list(sns.xkcd_rgb.values()), max(db_clusters)+1)) # Генерируем контрастную карту цветов.\n",
    "            print('количество кластеров ',max(db_clusters)+1)\n",
    "            N=15\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(N,N))\n",
    "\n",
    "            ax.scatter(umaped_vct[:-1, 0], umaped_vct[:-1, 1], s=300, c=db_clusters, cmap=myclr)\n",
    "            ax.scatter(umaped_vct[-1, 0], umaped_vct[-1, 1], s=600, c=1, cmap='rocket')\n",
    "            for i,xy in enumerate(umaped_vct[:-1]):\n",
    "                ax.text(xy[0], xy[1],'   '+str(faq_logits[i][1])+' ' +questions[i], fontsize=15,  color='black')\n",
    "\n",
    "            ax.text(umaped_vct[-1,0], umaped_vct[-1,1],'   Question: '+ question, fontsize=15,  color='black')\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Как оформить льготу \n",
      "---------------------\n",
      "0.8111 Как оформить льготу в Московской области?\n",
      "Wall time: 24.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "noise=' пук кряк пиво интерал'\n",
    "noise2=' а то я не умею'\n",
    "question=faq['Question'][51] +noise2+noise\n",
    "question='Как оформить льготу '\n",
    "#question='льгота  от расхода'\n",
    "#question='Как будут осуществляться начисления если счетчик сломается'\n",
    "\n",
    "\n",
    "eps=0.15\n",
    "minimal_score=0.75\n",
    "beta=1.5\n",
    "\n",
    "modes=['fasttext','sbert']\n",
    "mode=modes[1]\n",
    "\n",
    "output=find_faq(engine,question,eps,minimal_score,mode=mode,verbose=True,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_question(vectorizer,question,pred_questions,min_score):\n",
    "    question_words=question.split()\n",
    "    question_words_embs=[vectorizer(word) for word in question_words]\n",
    "    \n",
    "    pred_question_words=[]\n",
    "    for pred_question in pred_questions:\n",
    "        words=pred_question.split()\n",
    "        pred_question_words=pred_question_words+words\n",
    "    \n",
    "    pred_question_words_embs=[vectorizer(word) for word in pred_question_words]\n",
    "    \n",
    "    dlt_inx=[]\n",
    "    \n",
    "    for i,question_word_emb in enumerate(question_words_embs):\n",
    "        word_score=0\n",
    "        for j,pred_question_word_emb in enumerate(pred_question_words_embs):\n",
    "            score=1-spatial.distance.cosine(question_word_emb, pred_question_word_emb)\n",
    "            if score > word_score:\n",
    "                word_score=score\n",
    "                \n",
    "        if word_score<min_score:\n",
    "            dlt_inx.append(i)\n",
    "            \n",
    "    for i in reversed(dlt_inx):\n",
    "        question_words.pop(i)\n",
    "    \n",
    "    return \" \".join(question_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=['Сборка простой люстры',\n",
    "'Сборка сложной люстры',\n",
    "'Установка простой люстры',\n",
    "'Установка сложной люстры',\n",
    "'Установка светильника типа Армстронг',\n",
    "'Установка светильника настенного, бра',\n",
    "'Установка точечного светильника',\n",
    "'Подключение светильника Выход',\n",
    "'Подключени трансформатора для галогенных ламп',\n",
    "'Установка антивандального светильника']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=questions[:2]\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2=questions[4:7]\n",
    "q2_words=[]\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "for q in q2:\n",
    "    words=q.split()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0] \n",
    "        q2_words.append(p.normal_form)\n",
    "        \n",
    "q2_words=set(q2_words)\n",
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "word = \"светильником\"\n",
    "p = morph.parse(word)[0]  # Делаем полный разбор, и берем первый вариант разбора (условно \"самый вероятный\", но не факт что правильный)\n",
    "print(p.normal_form)  # стать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search engine\n",
    "\n",
    "FastText documents embeddings vs questions\n",
    "\n",
    "document=questions+answers on one theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[]\n",
    "documents=[]\n",
    "class_num=len(faq1)\n",
    "questions2class=dict()\n",
    "questions_classes=[]\n",
    "\n",
    "\n",
    "\n",
    "for i,document in enumerate(faq1):\n",
    "    \n",
    "    temp_questions=[]\n",
    "    for line in document:\n",
    "        question=line[0]\n",
    "        temp_questions.append(question)\n",
    "        questions2class[question]=i\n",
    "    questions.append(temp_questions)\n",
    "        \n",
    "        \n",
    "    temp_documents=[]\n",
    "    for line in document:\n",
    "        temp_documents.append(line[0])\n",
    "        temp_documents.append(line[1])\n",
    "\n",
    "        \n",
    "    documents.append(temp_documents)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_embs=np.zeros((len(documents),300))\n",
    "for i,document in enumerate(documents):\n",
    "    documents_embs[i]=sentence_embedding(ft_model,document)\n",
    "    \n",
    "questions_embs=[]\n",
    "for i,question_document in enumerate(questions):\n",
    "    temp_questions_embs=[]\n",
    "    for question in question_document:\n",
    "        temp_questions_embs.append(sentence_embedding(ft_model,[question]))\n",
    "    questions_embs.append(temp_questions_embs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,document in enumerate(documents_embs):\n",
    "\n",
    "    pairs_number=len(questions_embs[i])\n",
    "    pairs=[]\n",
    "    labels=[]\n",
    "    #  true pairs\n",
    "    for question in questions_embs[i]:\n",
    "        pairs.append([document,question])\n",
    "        labels.append(1)\n",
    "        \n",
    "    # false document\n",
    "    for j in range(pairs_number):\n",
    "        flag=True\n",
    "        rnd_indx=np.random.randint(0,len(documents_embs))\n",
    "        while  rnd_indx==i:\n",
    "                rnd_indx=np.random.randint(0,len(documents_embs))\n",
    "        pairs.append([documents_embs[rnd_indx],question])\n",
    "        labels.append(0)\n",
    "        \n",
    "    # false questions\n",
    "    for j in range(pairs_number):\n",
    "        flag=True\n",
    "        rnd_indx=np.random.randint(0,len(documents_embs))\n",
    "        while rnd_indx==i:\n",
    "                rnd_indx=np.random.randint(0,len(documents_embs))\n",
    "                \n",
    "        rnd_indx_question=np.random.randint(0,len(questions_embs[rnd_indx]))\n",
    "        pairs.append([document,questions_embs[rnd_indx][rnd_indx_question]])\n",
    "        labels.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=np.array(pairs).astype('float32')\n",
    "labels=np.array(labels).astype('float32')\n",
    "x_train,x_test,y_train,y_test=train_test_split(pairs,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss_with_margin(margin):\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "    \n",
    "        square_pred = K.square(y_pred)\n",
    "        margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "        return K.mean( (1 - y_true) * square_pred+y_true*margin_square)\n",
    "    \n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #\n",
    "    #   it is also good idea to use VGG model, but it requires powerfull GPU\n",
    "    #   model = Sequential(VGG16(weights='imagenet', include_top=False, input_shape=image_shape).layers)\n",
    "    #\n",
    "    model=Sequential()\n",
    "    \n",
    "    model.add(Reshape((15,20,1),input_shape=emb_shape))\n",
    "#    model.add(Conv2D(32,(3,3)))\n",
    "#    model.add(BatchNormalization())\n",
    "        \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_shape=(300,)\n",
    "base_network = get_model()\n",
    "\n",
    "input_a = Input(shape=emb_shape)\n",
    "vect_output_a = base_network(input_a)\n",
    "\n",
    "input_b = Input(shape=emb_shape)\n",
    "vect_output_b = base_network(input_b)\n",
    "\n",
    "x = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([vect_output_a, vect_output_b])\n",
    "output= Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = Model([input_a, input_b], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = RMSprop(  learning_rate=0.015)\n",
    "#optim = Adam(  learning_rate=0.015)\n",
    "model.compile(loss=contrastive_loss_with_margin(margin=1), optimizer=optim)\n",
    "history = model.fit([x_train[:,0],x_train[:,1]], \n",
    "                    y_train, \n",
    "                    epochs=30, \n",
    "                    batch_size=1,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() > 0.5\n",
    "    return round(np.mean(pred == y_true),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = round(model.evaluate(x=[x_test[:,0],x_test[:,1]], y=y_test),4)\n",
    "\n",
    "y_pred_train = model.predict([x_train[:,0],x_train[:,1]])\n",
    "train_accuracy = compute_accuracy(y_train, y_pred_train)\n",
    "\n",
    "y_pred_test = model.predict([x_test[:,0], x_test[:,1]])\n",
    "test_accuracy = compute_accuracy(y_test, y_pred_test)\n",
    "\n",
    "print(\"Loss = {}, Train Accuracy = {} Test Accuracy = {}\".format(loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paragraph ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import build_model, configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "[Reference](https://medium.com/swlh/fine-tuning-bert-for-text-classification-and-question-answering-using-tensorflow-framework-4d09daeb3330#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjFiZjhhODRkM2VjZDc3ZTlmMmFkNWYwNmZmZDI2MDcwMWRkMDZkOTAiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MjU5MDYxNDIsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNjU4MDUxNjE5NzU3NTk0MTk2NCIsImhkIjoibWllbS5oc2UucnUiLCJlbWFpbCI6ImRna2FncmFtYW55YW5AbWllbS5oc2UucnUiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiYXpwIjoiMjE2Mjk2MDM1ODM0LWsxazZxZTA2MHMydHAyYTJqYW00bGpkY21zMDBzdHRnLmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tIiwibmFtZSI6ItCU0LDQstC40LQg0JrQsNCz0YDQsNC80LDQvdGP0L0iLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EtL0FPaDE0R2hGdEZGSkZMaDlyUFV0QXdZLXlyZWlRczJObjEyQ2xpc3hmX3hQPXM5Ni1jIiwiZ2l2ZW5fbmFtZSI6ItCU0LDQstC40LQiLCJmYW1pbHlfbmFtZSI6ItCa0LDQs9GA0LDQvNCw0L3Rj9C9IiwiaWF0IjoxNjI1OTA2NDQyLCJleHAiOjE2MjU5MTAwNDIsImp0aSI6IjhiYmVjYmRjYWRiZTAyZDZkNjQ1MTMxY2Q2NzJhZTI4MWViMTdkNWYifQ.LRr773uwpuGgpYnO7WsltRMVbC3JdFg7DBIlPtnLhN11OpKyNZ5X3y2ZGLx72_tJaSXZS52xdLcEsLuM4Tk1Ta_4ifnuAMkkeJMYJct0DpJOqXGYWS9S2atl8JLvbQaLyNrseNHneLtzRgtj--Htk1Lq0red-VmGxO849tzhKfjfQDPw-PsKxnhKMxHoEHJs91z-djL_L8ATQ6p86TcSWzWGsi4Ya69TmkMiRw-W2eMaZjN11gjSXUCnJKUUC122fluOmDzsGnUbtpoSGD-86mTa368FTFLbQSC7M8SGiZKo_pIZCcKrGjBQM-bJFAMs3-I8J7nM6782Vlh_CZiBew)\n",
    "\n",
    "[просто ссылка с хорошей инфой]( https://lilianweng.github.io/lil-log/2020/10/29/open-domain-question-answering.html )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
