{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "from matplotlib.colors import ListedColormap\n",
    "from numpy.random import choice\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from gensim.models import FastText,KeyedVectors,fasttext\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "'''import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape,BatchNormalization,MaxPooling2D,Lambda\n",
    "from tensorflow.keras.layers import Dense,Activation,Reshape,Conv2D,LeakyReLU,concatenate,Flatten\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cluster\n",
    "\n",
    "import seaborn as sns\n",
    "import umap\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine():\n",
    "    def __init__(self,faq,sbert_name=False,fasttext_path=False):\n",
    "        self.faq=faq\n",
    "        if sbert_name:\n",
    "            start = time.time()\n",
    "            \n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            self.sbert_model = AutoModel.from_pretrained(sbert_name)\n",
    "            self.sbert_model.to(self.device)\n",
    "            self.sbert_tokenizer = AutoTokenizer.from_pretrained(sbert_name)\n",
    "            self.sbert_faq_embs=np.array([self.vectorize_sentence_sbert(sent) for sent in self.faq[:,0]])\n",
    "            \n",
    "            end = time.time()\n",
    "            self.MorphAnalyzer=morph = pymorphy2.MorphAnalyzer()\n",
    "            print('Sbert model and faq successfully loaded\\nPassed time:',round(end - start,2),'s')\n",
    "            \n",
    "            \n",
    "        if fasttext_path:\n",
    "            self.ft_model= fasttext.FastTextKeyedVectors.load(fasttext_path)\n",
    "            self.ft_faq_embs=np.array([self.vectorize_sentence_ft(sent) for sent in self.faq[:,0]])\n",
    "        \n",
    "    def vectorize_sentence_ft(self,sentence):\n",
    "        txt=sentence.split()\n",
    "        val=0\n",
    "        for word in txt:\n",
    "            val+=self.ft_model[word]\n",
    "\n",
    "        return val/len(txt)\n",
    "    \n",
    "\n",
    "    def vectorize_sentence_sbert(self,sentence):\n",
    "    \n",
    "        encoded_input = self.sbert_tokenizer(sentence,\n",
    "                                             padding=True,\n",
    "                                             truncation=True,\n",
    "                                             max_length=24,\n",
    "                                             return_tensors='pt').to(self.device)\n",
    "\n",
    "   #     with torch.no_grad():\n",
    "        model_output = self.sbert_model(**encoded_input)\n",
    "            \n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        sentence_embedding = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        sentence_embedding = np.squeeze(sentence_embedding)\n",
    "        \n",
    "        return sentence_embedding.cpu().data.numpy()\n",
    "    \n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def mean_pooling(cls,model_output, attention_mask):\n",
    "        #Mean Pooling - Take attention mask into account for correct averaging\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "    \n",
    "    def search_faq(self,question,eps,minimal_score,mode,beta):\n",
    "        if mode=='fasttext':\n",
    "            vectorizer=self.vectorize_sentence_ft\n",
    "            faq_embs=self.ft_faq_embs\n",
    "        elif mode=='sbert':\n",
    "            vectorizer=self.vectorize_sentence_sbert\n",
    "            faq_embs=self.sbert_faq_embs\n",
    "\n",
    "        question_emb=vectorizer(question)\n",
    "        score=np.zeros((self.faq.shape[0],1))\n",
    "\n",
    "       \n",
    "        for i,faq_emb in enumerate(faq_embs):\n",
    "            score[i,0]=self.cos_dist( faq_emb,question_emb)\n",
    "                 \n",
    "        \n",
    "        faq_logits=np.concatenate([faq,faq_embs,score],axis=1)\n",
    "        faq_logits=faq_logits[faq_logits[:, 3].argsort()]\n",
    "        faq_logits=faq_logits[::-1]\n",
    "\n",
    "\n",
    "        max_score=faq_logits[0,3]\n",
    "        display_num=0\n",
    "\n",
    "        for scr in faq_logits[:,2]:\n",
    "            if max_score-scr<eps and scr > minimal_score:\n",
    "                display_num+=1\n",
    "            else:\n",
    "                break\n",
    "         \n",
    "\n",
    "        \n",
    "        return faq_logits[:display_num]\n",
    "    \n",
    "    @classmethod\n",
    "    def cos_dist(cls,vect1,vect2):\n",
    "        return 1-spatial.distance.cosine(vect1,vect2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def calculate_faq(engine,question_emb,faq_embs,eps,minimal_score,mode):\n",
    "\n",
    "        score=np.zeros((engine.faq.shape[0],1))\n",
    "        for i,faq_emb in enumerate(faq_embs):\n",
    "            \n",
    "            distance=1-spatial.distance.cosine( faq_emb,question_emb)\n",
    "            score[i,0]=round(distance,4)\n",
    "                 \n",
    "        index=np.arange(len(engine.faq)).reshape((-1,1))\n",
    "        \n",
    "        questions=engine.faq[:,0].reshape((-1,1))\n",
    "        \n",
    "        faq_logits=np.concatenate([index,score],axis=1)\n",
    "        faq_logits=faq_logits[faq_logits[:, 1].argsort()]\n",
    "        faq_logits=faq_logits[::-1]\n",
    "\n",
    "\n",
    "        max_score=faq_logits[0,1]\n",
    "        display_num=0\n",
    "\n",
    "        for scr in faq_logits[:,1]:\n",
    "            if max_score-scr<eps and scr > minimal_score:\n",
    "                display_num+=1\n",
    "            else:\n",
    "                break\n",
    "         \n",
    "        faq_logits=faq_logits[:display_num]\n",
    "        \n",
    "        \n",
    "        return faq_logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faq(engine,question,eps,minimal_score,mode='sbert',verbose=False,plot=False):\n",
    "    \n",
    "    if mode=='fasttext':\n",
    "        vectorizer=engine.vectorize_sentence_ft\n",
    "        faq_embs=engine.ft_faq_embs\n",
    "    elif mode=='sbert':\n",
    "        vectorizer=engine.vectorize_sentence_sbert\n",
    "        faq_embs=engine.sbert_faq_embs\n",
    "            \n",
    "    question_emb=vectorizer(question)\n",
    "    faq_logits=calculate_faq(engine,question_emb,faq_embs,eps,minimal_score,mode)\n",
    "    questions_indeces=faq_logits[:,0].astype('int64').reshape((1,-1))\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print('Question: ',question)\n",
    "        print('---------------------')\n",
    "        questions=engine.faq[questions_indeces][0,:,0]\n",
    "        for i,faq_question in enumerate(questions):\n",
    "            print('index ',faq_logits[i,0],' score ', faq_logits[i,1],faq_question)\n",
    "    \n",
    "    n_clusters=2\n",
    "    if faq_logits.shape[0]>n_clusters:\n",
    "\n",
    "        clustering=cluster.KMeans(n_clusters)\n",
    "        #clustering = cluster.OPTICS(min_samples=3, xi=.05, min_cluster_size=.05)\n",
    "\n",
    "        db_clusters = clustering.fit_predict(faq_embs[questions_indeces][0])\n",
    "\n",
    "            \n",
    "        clusters_score=np.zeros((n_clusters))\n",
    "        clusters_size=np.zeros((n_clusters))\n",
    "        \n",
    "        for i,logit in enumerate(faq_logits):\n",
    "            index=db_clusters[i]\n",
    "            clusters_score[index]+=logit[1]\n",
    "            clusters_size[index]+=1\n",
    "        \n",
    "        clusters_mean_score=clusters_score/clusters_size\n",
    "        \n",
    "        max_score_index=0\n",
    "        max_score_val=0\n",
    "        \n",
    "        for i,cluster_val in enumerate(clusters_mean_score):\n",
    "            if cluster_val> max_score_val:\n",
    "                max_score_val=cluster_val\n",
    "                max_score_index=i\n",
    "        \n",
    "        true_faq_lofits=faq_logits[np.where(db_clusters==max_score_index)]\n",
    "        \n",
    "        true_questions_indeces=true_faq_lofits[:,0].astype('int64').reshape((1,-1))\n",
    "        \n",
    "            \n",
    "        if verbose:\n",
    "            print('\\nCleaned questions')\n",
    "            print('---------------------')\n",
    "            true_questions=engine.faq[true_questions_indeces][0,:,0]\n",
    "            for i,faq_question in enumerate(true_questions):\n",
    "                print('index ',faq_logits[i,0],' score ', faq_logits[i,1],faq_question)\n",
    "                \n",
    "        \n",
    "        if plot:\n",
    "\n",
    "            umap_news=umap.UMAP()\n",
    "            question_emb=vectorizer(question).reshape(1,-1)\n",
    "            data=np.concatenate([faq_embs[questions_indeces][0],question_emb],axis=0)\n",
    "            umaped_vct=umap_news.fit_transform(data)\n",
    "            questions=engine.faq[questions_indeces][0,:,0]\n",
    "\n",
    "            myclr=ListedColormap(choice(list(sns.xkcd_rgb.values()), max(db_clusters)+1)) # Генерируем контрастную карту цветов.\n",
    "            print('количество кластеров ',max(db_clusters)+1)\n",
    "            N=15\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(N,N))\n",
    "\n",
    "            ax.scatter(umaped_vct[:-1, 0], umaped_vct[:-1, 1], s=300, c=db_clusters, cmap=myclr)\n",
    "            ax.scatter(umaped_vct[-1, 0], umaped_vct[-1, 1], s=600, c=1, cmap='rocket')\n",
    "            for i,xy in enumerate(umaped_vct[:-1]):\n",
    "                ax.text(xy[0], xy[1],'   '+str(faq_logits[i][1])+' ' +questions[i], fontsize=15,  color='black')\n",
    "\n",
    "            ax.text(umaped_vct[-1,0], umaped_vct[-1,1],'   Question: '+ question, fontsize=15,  color='black')\n",
    "            plt.show()\n",
    "        \n",
    "        return true_questions_indeces\n",
    "    else:\n",
    "        return questions_indeces\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def questions_diff(vectorizer,questions_indeces,min_score,max_score,verbose):\n",
    "    \n",
    "    questions=engine.faq[questions_indeces][0,:,0]\n",
    "    \n",
    "    words_pool_embs=[]\n",
    "    questions_words_embs=[]\n",
    "    questions_words=[]\n",
    "    questions_words_embs_pool=[]\n",
    "    \n",
    "    \n",
    "    for question in questions:\n",
    "        words=question.split()\n",
    "        questions_words.append(words)\n",
    "        words_embs=[vectorizer(word) for word in words]\n",
    "        questions_words_embs.append(words_embs)\n",
    "        \n",
    "        words_pool_embs=words_pool_embs+words_embs\n",
    "    \n",
    "    common_words_indx=[]\n",
    "    \n",
    "    # поиск повторяющихся слов\n",
    "    for i,word1 in enumerate(words_pool_embs):\n",
    "        word_score=0\n",
    "        \n",
    "        for j,word2 in enumerate(words_pool_embs):\n",
    "            if i!=j:\n",
    "                score=1-spatial.distance.cosine(word1, word2)\n",
    "                if score > word_score:\n",
    "                    word_score=score\n",
    "\n",
    "        if word_score>min_score:\n",
    "            common_words_indx.append(i)\n",
    "            \n",
    "    words_pool_embs=np.array(words_pool_embs)\n",
    "  #  print('common indeces ',common_words_indx)\n",
    "    common_words_embs=words_pool_embs[common_words_indx]\n",
    "  #  print(len(common_words_embs))\n",
    "  #  print(len( words_pool_embs))\n",
    "    questions_diffs_eye=[]\n",
    "    \n",
    "    # повторный проход по вопросам\n",
    "    for i,question in enumerate(questions_words_embs):\n",
    "        questions_diffs_eye.append([])\n",
    "        \n",
    "        for word1 in question:\n",
    "            word_score=0\n",
    "            for word2 in common_words_embs:\n",
    "                score=1-spatial.distance.cosine(word1, word2)\n",
    "                if score > word_score:\n",
    "                    word_score=score\n",
    "                    \n",
    "            if word_score>max_score:\n",
    "                # если слово повтторяющееся\n",
    "                questions_diffs_eye[i].append(0)\n",
    "            else:\n",
    "                # если слово уникальное\n",
    "                questions_diffs_eye[i].append(1)\n",
    "                \n",
    "    questions_diffs_eye=np.array(questions_diffs_eye)\n",
    "    if verbose:\n",
    "        \n",
    "        print('\\ndiff indeces ',questions_diffs_eye)\n",
    "        print('-----------')\n",
    "    diff_words=[]\n",
    "    \n",
    "    for i,question_eye in enumerate(questions_diffs_eye):\n",
    "\n",
    "        question_eye=np.array(question_eye)\n",
    "        indeces=np.where(question_eye==1)[0]\n",
    "       \n",
    "        start=indeces[0]\n",
    "        end=indeces[-1]+1\n",
    "   #     print('indeces ',indeces)\n",
    "        diff_words.append(questions_words[i][start:end])\n",
    "    \n",
    "    diffs= [[\" \".join(words)] for words in diff_words]\n",
    "    for i,diff in enumerate(diffs):\n",
    "        diff.append(questions_indeces[0][i])\n",
    "    \n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_search(engine,diffs_logits,answer,mode='sbert'):\n",
    "    \n",
    "    if mode=='fasttext':\n",
    "        vectorizer=engine.vectorize_sentence_ft\n",
    "        faq_embs=engine.ft_faq_embs\n",
    "    elif mode=='sbert':\n",
    "        vectorizer=engine.vectorize_sentence_sbert\n",
    "        faq_embs=engine.sbert_faq_embs\n",
    "        \n",
    "    answer_emb=vectorizer(answer)\n",
    "    diffs_embs=[vectorizer(logit[0]) for logit in diffs_logits]\n",
    "    \n",
    "    index=0\n",
    "    score=0\n",
    "    \n",
    "    for i,diff_emb in enumerate(diffs_embs):\n",
    "        diff_score=engine.cos_dist(diff_emb,answer_emb)\n",
    "        if score<diff_score:\n",
    "            index=i\n",
    "            score=diff_score\n",
    "    \n",
    "    diff_index=diffs_logits[index][1]\n",
    "    question,answer=engine.faq[diff_index]\n",
    "    \n",
    "    return question,diff_index,answer,score\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system_question(engine,diffs):\n",
    "       # print('\\nQuestions difference')\n",
    "       # print('--------------')\n",
    "       # print(diffs)\n",
    "        morph = engine.MorphAnalyzer\n",
    "        system_question='Вас интересует '\n",
    "        n=len(diffs)\n",
    "\n",
    "        connectors=[]\n",
    "\n",
    "        if n==2:\n",
    "            connectors=['или ','?']\n",
    "        elif n==3:\n",
    "            connectors = [', ', ' или ','?']\n",
    "\n",
    "        for i,diff in enumerate(diffs):\n",
    "            diff_words=diff[0].split()\n",
    "            q=''\n",
    "            for word in diff_words:\n",
    "                p = morph.parse(word)[0]\n",
    "                if p.tag.POS=='NOUN':\n",
    "                    q+=p.normal_form+' '\n",
    "                else:\n",
    "                    q += word+' '\n",
    "\n",
    "            system_question+=q+connectors[i]\n",
    "            \n",
    "        return system_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sbert model and faq successfully loaded\n",
      "Passed time: 11.03 s\n"
     ]
    }
   ],
   "source": [
    "sbert_name = \"sberbank-ai/sbert_large_mt_nlu_ru\"\n",
    "# https://rusvectores.org/ru/models/\n",
    "#fasttext_path = 'fasttext/model.model'\n",
    "\n",
    "faq = pd.read_csv('faq.csv')\n",
    "engine = SearchEngine(faq.values, sbert_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "как оформить льготу\n",
      "Question:  как оформить льготу\n",
      "---------------------\n",
      "index  9.0  score  0.8307 Как оформить льготу в Москве?\n",
      "index  13.0  score  0.8111 Как оформить льготу в Московской области?\n",
      "index  11.0  score  0.7411 Какие документы необходимы для оформления/продления/переоформления льготы?\n",
      "\n",
      "Cleaned questions\n",
      "---------------------\n",
      "index  9.0  score  0.8307 Как оформить льготу в Москве?\n",
      "index  13.0  score  0.8111 Как оформить льготу в Московской области?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\cluster\\k_means_.py:442: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "C:\\Users\\Администратор\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:59: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вас интересует Москве? или Московской области? ?\n",
      "москве\n",
      "Как оформить льготу в Москве? 9 0.6206793785095215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#noise = ' пук кряк пиво интерал'\n",
    "#noise2 = ' а то я не умею'\n",
    "#question = faq['Question'][9]\n",
    "#question = 'Как оформить льготу '\n",
    "# question='льгота  от расхода'\n",
    "# question='Как будут осуществляться начисления если счетчик сломается'\n",
    "question=input()\n",
    "\n",
    "eps = 0.15\n",
    "minimal_score = 0.7\n",
    "\n",
    "# ищем похожие вопросы в датасете\n",
    "# если больше 1 совпадения, кластеризуем и выбираем кластер с наибольшей точностью\n",
    "output = find_faq(engine, question, eps, minimal_score, verbose=True, plot=False)\n",
    "\n",
    "# если после кластеризации больше 1 совпадения\n",
    "if len(output[0])>1:\n",
    "\n",
    "    # ищем отличающиеся в вопросах слова\n",
    "    diffs = questions_diff(engine.vectorize_sentence_sbert, questions_indeces=output, min_score=0.8, max_score=0.8,\n",
    "                           verbose=0)\n",
    "   \n",
    "    # формируем уточняющий вопрос \n",
    "    system_question=create_system_question(engine,diffs)\n",
    "    print(system_question)\n",
    "\n",
    "    flag=True\n",
    "    # сравниеаем ответ пользователя и отличающиеся части вопросов\n",
    "    while flag:\n",
    "        answer=input()\n",
    "        question,question_index,asnwer,score = diff_search(engine, diffs, answer)\n",
    "        if score>0.6:\n",
    "            flag=False\n",
    "            print(question,question_index,score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "noise=' пук кряк пиво интерал'\n",
    "noise2=' а то я не умею'\n",
    "question=faq['Question'][9] \n",
    "question='Как оформить льготу '\n",
    "#question='льгота  от расхода'\n",
    "#question='Как будут осуществляться начисления если счетчик сломается'\n",
    "\n",
    "\n",
    "eps=0.15\n",
    "minimal_score=0.7\n",
    "beta=1.5\n",
    "\n",
    "modes=['fasttext','sbert']\n",
    "mode=modes[1]\n",
    "\n",
    "output=find_faq(engine,question,eps,minimal_score,mode=mode,verbose=True,plot=False)\n",
    "diffs=questions_diff(engine.vectorize_sentence_sbert,questions_indeces=output,min_score=0.8,max_score=0.8,verbose=0)\n",
    "print('\\nQuestions difference')\n",
    "print('--------------')\n",
    "print(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "answer='московской области'\n",
    "question=diff_search(engine,diffs,answer,mode)\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1=engine.vectorize_sentence_sbert('москва')\n",
    "vect2=engine.vectorize_sentence_sbert('московская область')\n",
    "vect3=engine.vectorize_sentence_sbert('город')\n",
    "engine.cos_dist(vect1,vect3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph.parse('области')[0].normal_form\n",
    "# ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=['Сборка простой люстры',\n",
    "'Сборка сложной люстры',\n",
    "'Установка простой люстры',\n",
    "'Установка сложной люстры',\n",
    "'Установка светильника типа Армстронг',\n",
    "'Установка светильника настенного, бра',\n",
    "'Установка точечного светильника',\n",
    "'Подключение светильника Выход',\n",
    "'Подключени трансформатора для галогенных ламп',\n",
    "'Установка антивандального светильника']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1=questions[:2]\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2=questions[4:7]\n",
    "q2_words=[]\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "for q in q2:\n",
    "    words=q.split()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0] \n",
    "        q2_words.append(p.normal_form)\n",
    "        \n",
    "q2_words=set(q2_words)\n",
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "word = \"светильником\"\n",
    "p = morph.parse(word)[0]  # Делаем полный разбор, и берем первый вариант разбора (условно \"самый вероятный\", но не факт что правильный)\n",
    "print(p.normal_form)  # стать"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
